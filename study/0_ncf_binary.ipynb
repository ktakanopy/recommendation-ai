{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2dab989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch \n",
    "from feature_processor import FeatureProcessor\n",
    "\n",
    "from candidate_generator import CandidateGenerator\n",
    "from validate_model import validate_model_with_features\n",
    "from ncf import NCF\n",
    "from cold_start import ColdStartRecommender\n",
    "\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28f5c0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121813/496125939.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_csv(\"../two_towers/data/ml-1m/ratings.dat\", sep=\"::\", header=None)\n",
      "/tmp/ipykernel_121813/496125939.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies = pd.read_csv(\"../two_towers/data/ml-1m/movies.dat\", sep=\"::\", header=None)\n",
      "/tmp/ipykernel_121813/496125939.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users = pd.read_csv(\"../two_towers/data/ml-1m/users.dat\", sep=\"::\", header=None)\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"../two_towers/data/ml-1m/ratings.dat\", sep=\"::\", header=None)\n",
    "ratings.columns = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "\n",
    "movies = pd.read_csv(\"../two_towers/data/ml-1m/movies.dat\", sep=\"::\", header=None)\n",
    "movies.columns = [\"movie_id\", \"title\", \"genres\"]\n",
    "\n",
    "users = pd.read_csv(\"../two_towers/data/ml-1m/users.dat\", sep=\"::\", header=None)\n",
    "users.columns = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zip_code\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01a92d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  movie_id  rating  timestamp\n",
      "799       10      2622       5  978228212\n",
      "800       10       648       4  978224925\n",
      "801       10      2628       3  978228408\n",
      "802       10      3358       5  978226378\n",
      "803       10      3359       3  978227125\n"
     ]
    }
   ],
   "source": [
    "rand_userIds = np.random.choice(ratings['user_id'].unique(),\n",
    "                               size=int(len(ratings['user_id'].unique())*0.1),\n",
    "                               replace=False)\n",
    "ratings = ratings.loc[ratings['user_id'].isin(rand_userIds)]\n",
    "\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b30cc660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing user and movie features...\n",
      "Preparing user features...\n",
      "Fitting sklearn encoders...\n",
      "Gender categories: ['F' 'M']\n",
      "Age categories: [ 1 18 25 35 45 50 56]\n",
      "Occupation categories: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "User features shape: (6040, 30)\n",
      "User feature columns: ['user_id', 'gender', 'age_1', 'age_18', 'age_25', 'age_35', 'age_45', 'age_50', 'age_56', 'occ_0', 'occ_1', 'occ_2', 'occ_3', 'occ_4', 'occ_5', 'occ_6', 'occ_7', 'occ_8', 'occ_9', 'occ_10', 'occ_11', 'occ_12', 'occ_13', 'occ_14', 'occ_15', 'occ_16', 'occ_17', 'occ_18', 'occ_19', 'occ_20']\n",
      "User feature dtypes:\n",
      "user_id    float64\n",
      "gender     float64\n",
      "age_1      float64\n",
      "age_18     float64\n",
      "age_25     float64\n",
      "age_35     float64\n",
      "age_45     float64\n",
      "age_50     float64\n",
      "age_56     float64\n",
      "occ_0      float64\n",
      "occ_1      float64\n",
      "occ_2      float64\n",
      "occ_3      float64\n",
      "occ_4      float64\n",
      "occ_5      float64\n",
      "occ_6      float64\n",
      "occ_7      float64\n",
      "occ_8      float64\n",
      "occ_9      float64\n",
      "occ_10     float64\n",
      "occ_11     float64\n",
      "occ_12     float64\n",
      "occ_13     float64\n",
      "occ_14     float64\n",
      "occ_15     float64\n",
      "occ_16     float64\n",
      "occ_17     float64\n",
      "occ_18     float64\n",
      "occ_19     float64\n",
      "occ_20     float64\n",
      "dtype: object\n",
      "User feature dimension: 29\n",
      "Using device: cpu\n",
      "Preparing movie features with sentence transformers...\n",
      "Loading sentence transformer model...\n",
      "Encoding movie titles...\n",
      "Encoding movie genres...\n",
      "Title embeddings shape: torch.Size([3883, 384])\n",
      "Genre embeddings shape: torch.Size([3883, 384])\n",
      "Combined movie embeddings shape: torch.Size([3883, 768])\n",
      "Normalizing movie embeddings...\n",
      "Original embeddings - mean: 0.0010, std: 0.0510\n",
      "Normalized embeddings - mean: 0.0007, std: 0.0361\n",
      "Movie feature dimension: 768\n",
      "\n",
      "Feature preparation complete!\n",
      "User feature dimension: 29\n",
      "Movie feature dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Initialize feature processor and prepare features\n",
    "print(\"Preparing user and movie features...\")\n",
    "\n",
    "# Initialize feature processor\n",
    "feature_processor = FeatureProcessor()\n",
    "\n",
    "# Prepare user features\n",
    "user_features_df = feature_processor.prepare_user_features(users)\n",
    "\n",
    "# Prepare movie features  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "movie_embeddings = feature_processor.prepare_movie_features(movies, device=device)\n",
    "\n",
    "print(f\"\\nFeature preparation complete!\")\n",
    "print(f\"User feature dimension: {feature_processor.user_feature_dim}\")\n",
    "print(f\"Movie feature dimension: {feature_processor.movie_feature_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cc83867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 97208 entries, 799 to 998118\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   user_id    97208 non-null  int64\n",
      " 1   movie_id   97208 non-null  int64\n",
      " 2   rating     97208 non-null  int64\n",
      " 3   timestamp  97208 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f538cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rank_latest'] = ratings.groupby(['user_id'])['timestamp'] \\\n",
    "                                .rank(method = 'first',ascending=False)\n",
    "\n",
    "train_ratings = ratings[ratings['rank_latest'].isin([1,2])]\n",
    "validation_ratings = ratings[ratings['rank_latest'] == 1]\n",
    "test_ratings = ratings[ratings['rank_latest'] == 2]\n",
    "\n",
    "# drop columns that we no Longer need \n",
    "train_ratings = train_ratings[['user_id', 'movie_id', 'rating']]\n",
    "test_ratings = test_ratings[['user_id','movie_id','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "228a99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings['user_id'].max()+1\n",
    "num_items = ratings['movie_id'].max()+1\n",
    "\n",
    "all_movieIds = ratings['movie_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3df34dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "candidate_gen = CandidateGenerator(ratings, movies, all_movieIds)\n",
    "\n",
    "def generate_candidates(user_id, method=\"hybrid\", num_candidates=100):\n",
    "    \"\"\"Backward compatible interface\"\"\"\n",
    "    return candidate_gen.generate_candidates(user_id, method, num_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a555y7g5r7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing candidates for 604 validation users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0873ff5a8584ad6994c4254372590b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing candidates:   0%|          | 0/604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed candidates for 604 users\n"
     ]
    }
   ],
   "source": [
    "# Precompute validation candidates for faster validation\n",
    "def precompute_validation_candidates(validation_ratings, candidate_method=\"hybrid\", num_candidates=100):\n",
    "    \"\"\"\n",
    "    Precompute candidates for all validation users to speed up validation\n",
    "    \n",
    "    Returns:\n",
    "        dict: {user_id: [candidate_items]}\n",
    "    \"\"\"\n",
    "    validation_users = validation_ratings['user_id'].unique()\n",
    "    precomputed_candidates = {}\n",
    "    \n",
    "    print(f\"Precomputing candidates for {len(validation_users)} validation users...\")\n",
    "    \n",
    "    for user_id in tqdm(validation_users, desc=\"Precomputing candidates\"):\n",
    "        candidates = generate_candidates(user_id, method=candidate_method, num_candidates=num_candidates)\n",
    "        precomputed_candidates[user_id] = candidates\n",
    "    \n",
    "    print(f\"Precomputed candidates for {len(precomputed_candidates)} users\")\n",
    "    return precomputed_candidates\n",
    "\n",
    "# Precompute candidates before training\n",
    "validation_candidates = precompute_validation_candidates(validation_ratings, candidate_method=\"hybrid\", num_candidates=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fd673a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Training with UNIQUE_PER_USER sampling + HYBRID negatives\n",
      "======================================================================\n",
      "Generating training dataset with hybrid negative sampling\n",
      "Sampling strategy: unique_per_user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users: 100%|██████████| 604/604 [00:02<00:00, 237.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6040 samples (1208 positive, 4832 negative)\n",
      "Negative-to-positive ratio: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e421abc92640ec8dfe4d272060abb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 40.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.39024150371551514, Rank=19/101\n",
      "User 3912, Movie 318: Score=0.38181254267692566, Rank=26/101\n",
      "User 1878, Movie 1920: Score=0.3883642256259918, Rank=29/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.100\n",
      "Mean Rank: 38.6\n",
      "MRR: 0.087\n",
      "Epoch 1/30\n",
      "  Training Loss: 0.5574\n",
      "  Hit Ratio @ 10: 0.100\n",
      "  Mean Rank: 38.6\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c932cf6b4f477f87509c2bceb1e06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 40.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.320016086101532, Rank=11/101\n",
      "User 3912, Movie 318: Score=0.2788303792476654, Rank=33/101\n",
      "User 1878, Movie 1920: Score=0.3007119297981262, Rank=31/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.100\n",
      "Mean Rank: 32.5\n",
      "MRR: 0.089\n",
      "Epoch 2/30\n",
      "  Training Loss: 0.4394\n",
      "  Hit Ratio @ 10: 0.100\n",
      "  Mean Rank: 32.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579ab977c6bb4b1bba5ced9cfcf0711a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.3926253318786621, Rank=16/101\n",
      "User 3912, Movie 318: Score=0.3686119318008423, Rank=44/101\n",
      "User 1878, Movie 1920: Score=0.37502428889274597, Rank=30/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 39.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.200\n",
      "Mean Rank: 30.8\n",
      "MRR: 0.054\n",
      "Epoch 3/30\n",
      "  Training Loss: 0.4029\n",
      "  Hit Ratio @ 10: 0.200\n",
      "  Mean Rank: 30.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ecb262897d40b3b12f9b9808866de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.4161815345287323, Rank=13/101\n",
      "User 3912, Movie 318: Score=0.376687616109848, Rank=58/101\n",
      "User 1878, Movie 1920: Score=0.41639643907546997, Rank=15/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.250\n",
      "Mean Rank: 26.5\n",
      "MRR: 0.080\n",
      "Epoch 4/30\n",
      "  Training Loss: 0.3769\n",
      "  Hit Ratio @ 10: 0.250\n",
      "  Mean Rank: 26.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62187d9825b54ff298c1146fe9728706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 5/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.44042345881462097, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.22568640112876892, Rank=73/101\n",
      "User 1878, Movie 1920: Score=0.4424423575401306, Rank=13/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.250\n",
      "Mean Rank: 26.5\n",
      "MRR: 0.097\n",
      "Epoch 5/30\n",
      "  Training Loss: 0.3676\n",
      "  Hit Ratio @ 10: 0.250\n",
      "  Mean Rank: 26.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198c38efef664bfa84775e37791bb40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 6/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.4546666145324707, Rank=11/101\n",
      "User 3912, Movie 318: Score=0.19287574291229248, Rank=58/101\n",
      "User 1878, Movie 1920: Score=0.46924665570259094, Rank=2/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.250\n",
      "Mean Rank: 21.0\n",
      "MRR: 0.122\n",
      "Epoch 6/30\n",
      "  Training Loss: 0.3651\n",
      "  Hit Ratio @ 10: 0.250\n",
      "  Mean Rank: 21.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434b201a0ad940af98c4e961b017e936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 7/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.4700664281845093, Rank=18/101\n",
      "User 3912, Movie 318: Score=0.15355516970157623, Rank=65/101\n",
      "User 1878, Movie 1920: Score=0.4830549657344818, Rank=8/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 40.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.200\n",
      "Mean Rank: 23.3\n",
      "MRR: 0.094\n",
      "Epoch 7/30\n",
      "  Training Loss: 0.3530\n",
      "  Hit Ratio @ 10: 0.200\n",
      "  Mean Rank: 23.3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483f650e38b84747a105963e2df510f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 8/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 40.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.49454158544540405, Rank=20/101\n",
      "User 3912, Movie 318: Score=0.07617317140102386, Rank=69/101\n",
      "User 1878, Movie 1920: Score=0.5052772760391235, Rank=12/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.200\n",
      "Mean Rank: 24.1\n",
      "MRR: 0.107\n",
      "Epoch 8/30\n",
      "  Training Loss: 0.3423\n",
      "  Hit Ratio @ 10: 0.200\n",
      "  Mean Rank: 24.1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20925c45753b40e582eda20816b8b532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 9/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 40.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5224889516830444, Rank=14/101\n",
      "User 3912, Movie 318: Score=0.09268729388713837, Rank=63/101\n",
      "User 1878, Movie 1920: Score=0.5381098985671997, Rank=12/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.200\n",
      "Mean Rank: 20.0\n",
      "MRR: 0.150\n",
      "Epoch 9/30\n",
      "  Training Loss: 0.3341\n",
      "  Hit Ratio @ 10: 0.200\n",
      "  Mean Rank: 20.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa696fd9d344fa0bb3ae03279ed2bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 10/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5720018744468689, Rank=10/101\n",
      "User 3912, Movie 318: Score=0.09877099841833115, Rank=62/101\n",
      "User 1878, Movie 1920: Score=0.5772178173065186, Rank=9/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 18.4\n",
      "MRR: 0.149\n",
      "Epoch 10/30\n",
      "  Training Loss: 0.3283\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 18.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859d142d95de4908a2cb305752dd68a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 11/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5817703008651733, Rank=15/101\n",
      "User 3912, Movie 318: Score=0.09729834645986557, Rank=63/101\n",
      "User 1878, Movie 1920: Score=0.5860705971717834, Rank=12/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.200\n",
      "Mean Rank: 21.0\n",
      "MRR: 0.124\n",
      "Epoch 11/30\n",
      "  Training Loss: 0.3251\n",
      "  Hit Ratio @ 10: 0.200\n",
      "  Mean Rank: 21.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926ff7182f5346a0905bb988ccbbc178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 12/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5766670107841492, Rank=15/101\n",
      "User 3912, Movie 318: Score=0.10292726010084152, Rank=62/101\n",
      "User 1878, Movie 1920: Score=0.5127536058425903, Rank=25/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.400\n",
      "Mean Rank: 17.1\n",
      "MRR: 0.133\n",
      "Epoch 12/30\n",
      "  Training Loss: 0.3197\n",
      "  Hit Ratio @ 10: 0.400\n",
      "  Mean Rank: 17.1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32064151af3e42df8caef5af72eda956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 13/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 40.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6119335889816284, Rank=15/101\n",
      "User 3912, Movie 318: Score=0.09034378826618195, Rank=67/101\n",
      "User 1878, Movie 1920: Score=0.46933114528656006, Rank=33/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.300\n",
      "Mean Rank: 21.8\n",
      "MRR: 0.130\n",
      "Epoch 13/30\n",
      "  Training Loss: 0.3103\n",
      "  Hit Ratio @ 10: 0.300\n",
      "  Mean Rank: 21.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a276d0cc454d06bff8863428ed4049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 14/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5916625261306763, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.19139578938484192, Rank=49/101\n",
      "User 1878, Movie 1920: Score=0.5773981809616089, Rank=19/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 15.2\n",
      "MRR: 0.129\n",
      "Epoch 14/30\n",
      "  Training Loss: 0.3044\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 15.2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbb1993af814ce9b6ea4cb7defdb89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 15/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6447447538375854, Rank=10/101\n",
      "User 3912, Movie 318: Score=0.0924079567193985, Rank=62/101\n",
      "User 1878, Movie 1920: Score=0.5098416805267334, Rank=25/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 39.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 17.9\n",
      "MRR: 0.139\n",
      "Epoch 15/30\n",
      "  Training Loss: 0.2916\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 17.9\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1ef85ae10d48d997183f4dafa29b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 16/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6680415868759155, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.0682002604007721, Rank=64/101\n",
      "User 1878, Movie 1920: Score=0.5408997535705566, Rank=21/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 17.0\n",
      "MRR: 0.157\n",
      "Epoch 16/30\n",
      "  Training Loss: 0.2888\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 17.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f223cc223b0744bdad88ac35d860be9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 17/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 41.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6536995768547058, Rank=13/101\n",
      "User 3912, Movie 318: Score=0.09662333130836487, Rank=63/101\n",
      "User 1878, Movie 1920: Score=0.543708086013794, Rank=21/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.400\n",
      "Mean Rank: 17.7\n",
      "MRR: 0.147\n",
      "Epoch 17/30\n",
      "  Training Loss: 0.2827\n",
      "  Hit Ratio @ 10: 0.400\n",
      "  Mean Rank: 17.7\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bc7b12cee146de97d6b02b1745eb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 18/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.44472983479499817, Rank=19/101\n",
      "User 3912, Movie 318: Score=0.13351815938949585, Rank=61/101\n",
      "User 1878, Movie 1920: Score=0.6491295695304871, Rank=15/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.550\n",
      "Mean Rank: 15.6\n",
      "MRR: 0.171\n",
      "Epoch 18/30\n",
      "  Training Loss: 0.2802\n",
      "  Hit Ratio @ 10: 0.550\n",
      "  Mean Rank: 15.6\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9289350548d44aeebf837e4f8660f8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 19/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 40%|████      | 8/20 [00:00<00:00, 39.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7148324847221375, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.06779976934194565, Rank=65/101\n",
      "User 1878, Movie 1920: Score=0.39632555842399597, Rank=31/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 39.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 17.5\n",
      "MRR: 0.135\n",
      "Epoch 19/30\n",
      "  Training Loss: 0.2720\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 17.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ed5e79a50d4d028e44740a4aa8b9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 20/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6669723987579346, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.13474677503108978, Rank=56/101\n",
      "User 1878, Movie 1920: Score=0.6270558834075928, Rank=14/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.600\n",
      "Mean Rank: 14.9\n",
      "MRR: 0.127\n",
      "Epoch 20/30\n",
      "  Training Loss: 0.2752\n",
      "  Hit Ratio @ 10: 0.600\n",
      "  Mean Rank: 14.9\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2590d49a8e2e4ed188589284b77495b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 21/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7455516457557678, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.10260410606861115, Rank=59/101\n",
      "User 1878, Movie 1920: Score=0.3302871882915497, Rank=30/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.550\n",
      "Mean Rank: 16.2\n",
      "MRR: 0.139\n",
      "Epoch 21/30\n",
      "  Training Loss: 0.2618\n",
      "  Hit Ratio @ 10: 0.550\n",
      "  Mean Rank: 16.2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d00dd0817794a03a3534c060b5d69ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 22/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7472551465034485, Rank=10/101\n",
      "User 3912, Movie 318: Score=0.12818561494350433, Rank=58/101\n",
      "User 1878, Movie 1920: Score=0.5799974799156189, Rank=23/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 17.8\n",
      "MRR: 0.115\n",
      "Epoch 22/30\n",
      "  Training Loss: 0.2590\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 17.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4570c09439044acb7e0d7c6b29b1bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 23/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.8194998502731323, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.11521369963884354, Rank=57/101\n",
      "User 1878, Movie 1920: Score=0.6517413258552551, Rank=19/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.600\n",
      "Mean Rank: 15.9\n",
      "MRR: 0.141\n",
      "Epoch 23/30\n",
      "  Training Loss: 0.2572\n",
      "  Hit Ratio @ 10: 0.600\n",
      "  Mean Rank: 15.9\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b51409e0404df299c2a30620eb257c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 24/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7937357425689697, Rank=10/101\n",
      "User 3912, Movie 318: Score=0.0793594941496849, Rank=60/101\n",
      "User 1878, Movie 1920: Score=0.5654357075691223, Rank=25/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 18.2\n",
      "MRR: 0.090\n",
      "Epoch 24/30\n",
      "  Training Loss: 0.2533\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 18.2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751e771db660467b812be51df1ad934c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 25/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7652862071990967, Rank=10/101\n",
      "User 3912, Movie 318: Score=0.05492164567112923, Rank=63/101\n",
      "User 1878, Movie 1920: Score=0.39381900429725647, Rank=25/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 18.1\n",
      "MRR: 0.125\n",
      "Epoch 25/30\n",
      "  Training Loss: 0.2526\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 18.1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afc469c0a8a471399361b5b86d99c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 26/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7965471148490906, Rank=11/101\n",
      "User 3912, Movie 318: Score=0.06388700753450394, Rank=61/101\n",
      "User 1878, Movie 1920: Score=0.5050593018531799, Rank=21/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.350\n",
      "Mean Rank: 18.0\n",
      "MRR: 0.119\n",
      "Epoch 26/30\n",
      "  Training Loss: 0.2518\n",
      "  Hit Ratio @ 10: 0.350\n",
      "  Mean Rank: 18.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33f36c3c54647aeaa398fefcb62f89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 27/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 40.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7652727365493774, Rank=10/101\n",
      "User 3912, Movie 318: Score=0.08299318701028824, Rank=60/101\n",
      "User 1878, Movie 1920: Score=0.4604056179523468, Rank=25/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 16.5\n",
      "MRR: 0.119\n",
      "Epoch 27/30\n",
      "  Training Loss: 0.2455\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 16.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed4d3aa14bb4f16b65c0fc9429b485e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 28/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.802591860294342, Rank=11/101\n",
      "User 3912, Movie 318: Score=0.10545267164707184, Rank=57/101\n",
      "User 1878, Movie 1920: Score=0.4347088038921356, Rank=26/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 16.0\n",
      "MRR: 0.134\n",
      "Epoch 28/30\n",
      "  Training Loss: 0.2322\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 16.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2343f8b449884f2a8f634ba64def9660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 29/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.8691232204437256, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.07710125297307968, Rank=60/101\n",
      "User 1878, Movie 1920: Score=0.4689476191997528, Rank=22/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 16.9\n",
      "MRR: 0.134\n",
      "Epoch 29/30\n",
      "  Training Loss: 0.2427\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 16.9\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699b2962ce4c48ae985706f2e11786de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 30/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7707292437553406, Rank=10/101\n",
      "User 3912, Movie 318: Score=0.09511437267065048, Rank=54/101\n",
      "User 1878, Movie 1920: Score=0.5016394257545471, Rank=18/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 16.2\n",
      "MRR: 0.117\n",
      "Epoch 30/30\n",
      "  Training Loss: 0.2365\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 16.2\n",
      "--------------------------------------------------\n",
      "Training with unique_per_user_hybrid completed!\n",
      "Final Hit Ratio @ 10: 0.500\n",
      "Final Mean Rank: 16.2\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "======================================================================\n",
      "unique_per_user_hybrid         | Hit Ratio: 0.500 | Mean Rank: 16.2\n",
      "\n",
      "All experiments completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_strategies = [\n",
    "    (\"unique_per_user\", \"hybrid\"),\n",
    "]\n",
    "NUM_EPOCHS = 30\n",
    "results = {}\n",
    "\n",
    "for sampling_strategy, neg_method in sampling_strategies:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training with {sampling_strategy.upper()} sampling + {neg_method.upper()} negatives\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Create optimized model with CORRECT feature dimensions\n",
    "    model = NCF(\n",
    "        user_feature_dim=feature_processor.user_feature_dim,\n",
    "        movie_feature_dim=feature_processor.movie_feature_dim,\n",
    "        ratings=train_ratings, \n",
    "        feature_processor=feature_processor,\n",
    "        candidate_generator=candidate_gen,\n",
    "        negative_method=neg_method, \n",
    "        sampling_strategy=sampling_strategy\n",
    "    )\n",
    "\n",
    "    # Set up training parameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    dataloader = model.get_dataloader(batch_size=512, num_workers=4, num_negatives=4)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    \n",
    "    epoch_results = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in tqdm(dataloader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            # Move batch to device\n",
    "            user_input, item_input, labels = [x.to(device) for x in batch]\n",
    "            batch_device = (user_input, item_input, labels)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass and compute loss\n",
    "            loss = model.compute_loss(batch_device)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            hit_ratio, mrr, mean_rank = validate_model_with_features(\n",
    "                model, validation_ratings, validation_candidates, device, \n",
    "                total_users_to_test=20, k=10\n",
    "            )\n",
    "        \n",
    "        epoch_results.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_loss,\n",
    "            'hit_ratio': hit_ratio,\n",
    "            'mean_rank': mean_rank\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Training Loss: {avg_loss:.4f}\")\n",
    "        print(f\"  Hit Ratio @ 10: {hit_ratio:.3f}\")\n",
    "        print(f\"  Mean Rank: {mean_rank:.1f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Store results\n",
    "    strategy_name = f\"{sampling_strategy}_{neg_method}\"\n",
    "    results[strategy_name] = epoch_results\n",
    "    \n",
    "    print(f\"Training with {strategy_name} completed!\")\n",
    "    print(f\"Final Hit Ratio @ 10: {hit_ratio:.3f}\")\n",
    "    print(f\"Final Mean Rank: {mean_rank:.1f}\")\n",
    "\n",
    "# Summary of results\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for strategy_name, epoch_results in results.items():\n",
    "    final_result = epoch_results[-1]\n",
    "    print(f\"{strategy_name:30} | Hit Ratio: {final_result['hit_ratio']:.3f} | Mean Rank: {final_result['mean_rank']:.1f}\")\n",
    "\n",
    "print(\"\\nAll experiments completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d42bd8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL SAVE AND LOAD DEMONSTRATION\n",
      "================================================================================\n",
      "\n",
      "1. SAVING MODEL\n",
      "--------------------------------------------------\n",
      "Model weights saved to models/ncf_trained_model.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL SAVE AND LOAD DEMONSTRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = \"models/ncf_trained_model.pth\"\n",
    "print(f\"\\n1. SAVING MODEL\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "model.save_weights(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9638ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model performance on test set...\n",
      "Precomputing candidates for 604 test users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae1cc0533914c6983a9cfd2f7364a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing test candidates:   0%|          | 0/604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:00<00:01, 39.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 2898, Movie 2502: Score=0.9038405418395996, Rank=4/101\n",
      "User 4689, Movie 3793: Score=0.8114569187164307, Rank=5/101\n",
      "User 3138, Movie 1580: Score=0.22729003429412842, Rank=26/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 50\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 50\n",
      "Hit Ratio @ 10: 0.580\n",
      "Mean Rank: 15.7\n",
      "MRR: 0.230\n",
      "TEST SET RESULTS:\n",
      "Hit Ratio @ 10: 0.580\n",
      "Mean Rank: 15.7\n",
      "MRR: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing model performance on test set...\")\n",
    "\n",
    "def precompute_test_candidates(test_ratings, candidate_method=\"hybrid\", num_candidates=100):\n",
    "    test_users = test_ratings['user_id'].unique()\n",
    "    precomputed_candidates = {}\n",
    "    \n",
    "    print(f\"Precomputing candidates for {len(test_users)} test users...\")\n",
    "    \n",
    "    for user_id in tqdm(test_users, desc=\"Precomputing test candidates\"):\n",
    "        candidates = generate_candidates(user_id, method=candidate_method, num_candidates=num_candidates)\n",
    "        precomputed_candidates[user_id] = candidates\n",
    "    \n",
    "    return precomputed_candidates\n",
    "\n",
    "test_candidates = precompute_test_candidates(test_ratings, candidate_method=\"hybrid\", num_candidates=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(f\"Evaluating on test set...\")\n",
    "    test_hit_ratio, test_mrr, test_mean_rank = validate_model_with_features(\n",
    "        model, test_ratings, test_candidates, device, \n",
    "        total_users_to_test=50, k=10\n",
    "    )\n",
    "\n",
    "print(f\"TEST SET RESULTS:\")\n",
    "print(f\"Hit Ratio @ 10: {test_hit_ratio:.3f}\")\n",
    "print(f\"Mean Rank: {test_mean_rank:.1f}\")\n",
    "print(f\"MRR: {test_mrr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "911dac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. LOADING COMPLETE MODEL (CLASS METHOD)\n",
      "--------------------------------------------------\n",
      "Complete model loaded successfully from models/ncf_trained_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate loading complete model using class method\n",
    "print(f\"\\n4. LOADING COMPLETE MODEL (CLASS METHOD)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "loaded_model = NCF.load_model(\n",
    "    filepath=model_save_path,\n",
    "    ratings=train_ratings,\n",
    "    feature_processor=feature_processor,\n",
    "    candidate_generator=candidate_gen\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc89c335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cold Start Recommender initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the cold start recommender with the trained model\n",
    "cold_start_recommender = ColdStartRecommender(\n",
    "    trained_model=loaded_model,\n",
    "    feature_processor=feature_processor,\n",
    "    candidate_generator=candidate_gen,\n",
    "    movies_df=movies\n",
    ")\n",
    "\n",
    "print(\"Cold Start Recommender initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "736eaa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COLD START RECOMMENDATION SYSTEM DEMONSTRATION\n",
      "================================================================================\n",
      "\n",
      "1. PURE COLD START SCENARIO\n",
      "--------------------------------------------------\n",
      "New User Demographics: {'gender': 'M', 'age': 25, 'occupation': 4}\n",
      "\n",
      "Top 10 Cold Start Recommendations:\n",
      " 1. Battlefield Earth (2000)                           (Score: 0.968)\n",
      " 2. Mutiny on the Bounty (1935)                        (Score: 0.968)\n",
      " 3. Maltese Falcon, The (1941)                         (Score: 0.964)\n",
      " 4. King Kong (1933)                                   (Score: 0.961)\n",
      " 5. Muppet Movie, The (1979)                           (Score: 0.960)\n",
      " 6. Platoon (1986)                                     (Score: 0.956)\n",
      " 7. Dumbo (1941)                                       (Score: 0.955)\n",
      " 8. Vertigo (1958)                                     (Score: 0.953)\n",
      " 9. Akira (1988)                                       (Score: 0.947)\n",
      "10. Doctor Zhivago (1965)                              (Score: 0.945)\n",
      "\n",
      "\n",
      "2. ONBOARDING MOVIES FOR RATING COLLECTION\n",
      "--------------------------------------------------\n",
      "Movies to show new user for initial ratings (diverse genres):\n",
      "1. American Beauty (1999)                   | Genres: Comedy|Drama\n",
      "2. Star Wars: Episode V - The Empire Strikes Back (1980) | Genres: Action|Adventure|Drama|Sci-Fi|War\n",
      "3. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "4. Star Wars: Episode IV - A New Hope (1977) | Genres: Action|Adventure|Fantasy|Sci-Fi\n",
      "5. Shakespeare in Love (1998)               | Genres: Comedy|Romance\n",
      "6. Terminator 2: Judgment Day (1991)        | Genres: Action|Sci-Fi|Thriller\n",
      "7. Saving Private Ryan (1998)               | Genres: Action|Drama|War\n",
      "8. E.T. the Extra-Terrestrial (1982)        | Genres: Children's|Drama|Fantasy|Sci-Fi\n",
      "\n",
      "\n",
      "3. WARM COLD START SCENARIO\n",
      "--------------------------------------------------\n",
      "User's initial ratings:\n",
      "  American Beauty (1999)                             - Rating: 5/5\n",
      "  Star Wars: Episode V - The Empire Strikes Back (1980) - Rating: 4/5\n",
      "  Shakespeare in Love (1998)                         - Rating: 4/5\n",
      "  Terminator 2: Judgment Day (1991)                  - Rating: 4/5\n",
      "  Saving Private Ryan (1998)                         - Rating: 4/5\n",
      "  E.T. the Extra-Terrestrial (1982)                  - Rating: 4/5\n",
      "\n",
      "Top 10 Recommendations after initial ratings:\n",
      " 1. Maltese Falcon, The (1941)                         (Score: 0.964)\n",
      " 2. Vertigo (1958)                                     (Score: 0.953)\n",
      " 3. Akira (1988)                                       (Score: 0.947)\n",
      " 4. Doctor Zhivago (1965)                              (Score: 0.945)\n",
      " 5. Unbearable Lightness of Being, The (1988)          (Score: 0.920)\n",
      " 6. Ben-Hur (1959)                                     (Score: 0.919)\n",
      " 7. Howards End (1992)                                 (Score: 0.869)\n",
      " 8. Rebel Without a Cause (1955)                       (Score: 0.849)\n",
      " 9. Animal House (1978)                                (Score: 0.834)\n",
      "10. Great Escape, The (1963)                           (Score: 0.728)\n",
      "\n",
      "\n",
      "4. COMPARISON: Different User Demographics\n",
      "--------------------------------------------------\n",
      "Different User Demographics: {'gender': 'F', 'age': 45, 'occupation': 0}\n",
      "\n",
      "Top 5 Recommendations for different demographic:\n",
      "1. Torn Curtain (1966)                                (Score: 0.962)\n",
      "2. SLC Punk! (1998)                                   (Score: 0.958)\n",
      "3. Mission to Mars (2000)                             (Score: 0.955)\n",
      "4. White Sands (1992)                                 (Score: 0.954)\n",
      "5. Assassins (1995)                                   (Score: 0.949)\n",
      "\n",
      "================================================================================\n",
      "Cold Start Recommendation Demonstration Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# DEMONSTRATION: Cold Start Recommendation Examples\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COLD START RECOMMENDATION SYSTEM DEMONSTRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Example 1: Pure Cold Start - New user with only demographics\n",
    "print(\"\\n1. PURE COLD START SCENARIO\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "new_user_demographics = {\n",
    "    'gender': 'M',     # Male\n",
    "    'age': 25,         # 25 years old  \n",
    "    'occupation': 4    # College/grad student (based on MovieLens occupation codes)\n",
    "}\n",
    "\n",
    "print(f\"New User Demographics: {new_user_demographics}\")\n",
    "\n",
    "# Get recommendations without any ratings\n",
    "cold_start_recommendations = cold_start_recommender.recommend_for_new_user(\n",
    "    user_demographics=new_user_demographics,\n",
    "    user_ratings=None,  # No ratings yet\n",
    "    num_recommendations=10\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 10 Cold Start Recommendations:\")\n",
    "for i, (movie_id, title, score) in enumerate(cold_start_recommendations, 1):\n",
    "    print(f\"{i:2d}. {title:<50} (Score: {score:.3f})\")\n",
    "\n",
    "# Example 2: Get onboarding movies for initial rating collection\n",
    "print(f\"\\n\\n2. ONBOARDING MOVIES FOR RATING COLLECTION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "onboarding_movies = cold_start_recommender.get_onboarding_movies(num_movies=8)\n",
    "\n",
    "print(\"Movies to show new user for initial ratings (diverse genres):\")\n",
    "for i, (movie_id, title, genres) in enumerate(onboarding_movies, 1):\n",
    "    print(f\"{i}. {title:<40} | Genres: {genres}\")\n",
    "\n",
    "# Example 3: Warm Cold Start - User has provided some initial ratings\n",
    "print(f\"\\n\\n3. WARM COLD START SCENARIO\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Simulate user rating some of the onboarding movies\n",
    "initial_ratings = [\n",
    "    (onboarding_movies[0][0], 5),  # Loved the first movie\n",
    "    (onboarding_movies[1][0], 4),  # Liked the second movie\n",
    "    (onboarding_movies[4][0], 4),  # Liked the fourth movie\n",
    "    (onboarding_movies[5][0], 4),  # Liked the fourth movie\n",
    "    (onboarding_movies[6][0], 4),  # Liked the fourth movie\n",
    "    (onboarding_movies[7][0], 4),  # Liked the fourth movie\n",
    "]\n",
    "\n",
    "print(\"User's initial ratings:\")\n",
    "for movie_id, rating in initial_ratings:\n",
    "    movie_title = movies[movies['movie_id'] == movie_id]['title'].iloc[0]\n",
    "    print(f\"  {movie_title:<50} - Rating: {rating}/5\")\n",
    "\n",
    "# Get improved recommendations based on initial ratings\n",
    "warm_recommendations = cold_start_recommender.recommend_for_new_user(\n",
    "    user_demographics=new_user_demographics,\n",
    "    user_ratings=initial_ratings,\n",
    "    num_recommendations=10\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 10 Recommendations after initial ratings:\")\n",
    "for i, (movie_id, title, score) in enumerate(warm_recommendations, 1):\n",
    "    print(f\"{i:2d}. {title:<50} (Score: {score:.3f})\")\n",
    "\n",
    "print(f\"\\n\\n4. COMPARISON: Different User Demographics\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Example with different demographics\n",
    "female_user_demographics = {\n",
    "    'gender': 'F',     # Female\n",
    "    'age': 45,         # 45 years old\n",
    "    'occupation': 0    # Other/not specified\n",
    "}\n",
    "\n",
    "print(f\"Different User Demographics: {female_user_demographics}\")\n",
    "\n",
    "female_recommendations = cold_start_recommender.recommend_for_new_user(\n",
    "    user_demographics=female_user_demographics,\n",
    "    user_ratings=None,\n",
    "    num_recommendations=5\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 5 Recommendations for different demographic:\")\n",
    "for i, (movie_id, title, score) in enumerate(female_recommendations, 1):\n",
    "    print(f\"{i}. {title:<50} (Score: {score:.3f})\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Cold Start Recommendation Demonstration Complete!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d8e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
