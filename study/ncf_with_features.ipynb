{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dab989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch \n",
    "from feature_processor import FeatureProcessor\n",
    "\n",
    "from candidate_generator import CandidateGenerator\n",
    "from validate_model import validate_model_with_features\n",
    "from ncf import NCF\n",
    "from cold_start import ColdStartRecommender\n",
    "\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f5c0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97100/496125939.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_csv(\"../two_towers/data/ml-1m/ratings.dat\", sep=\"::\", header=None)\n",
      "/tmp/ipykernel_97100/496125939.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies = pd.read_csv(\"../two_towers/data/ml-1m/movies.dat\", sep=\"::\", header=None)\n",
      "/tmp/ipykernel_97100/496125939.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users = pd.read_csv(\"../two_towers/data/ml-1m/users.dat\", sep=\"::\", header=None)\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"../two_towers/data/ml-1m/ratings.dat\", sep=\"::\", header=None)\n",
    "ratings.columns = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "\n",
    "movies = pd.read_csv(\"../two_towers/data/ml-1m/movies.dat\", sep=\"::\", header=None)\n",
    "movies.columns = [\"movie_id\", \"title\", \"genres\"]\n",
    "\n",
    "users = pd.read_csv(\"../two_towers/data/ml-1m/users.dat\", sep=\"::\", header=None)\n",
    "users.columns = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zip_code\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a92d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  movie_id  rating  timestamp\n",
      "799       10      2622       5  978228212\n",
      "800       10       648       4  978224925\n",
      "801       10      2628       3  978228408\n",
      "802       10      3358       5  978226378\n",
      "803       10      3359       3  978227125\n"
     ]
    }
   ],
   "source": [
    "rand_userIds = np.random.choice(ratings['user_id'].unique(),\n",
    "                               size=int(len(ratings['user_id'].unique())*0.1),\n",
    "                               replace=False)\n",
    "ratings = ratings.loc[ratings['user_id'].isin(rand_userIds)]\n",
    "\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30cc660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing user and movie features...\n",
      "Preparing user features...\n",
      "User features shape: (6040, 30)\n",
      "User feature columns: ['user_id', 'gender', 'age_1', 'age_18', 'age_25', 'age_35', 'age_45', 'age_50', 'age_56', 'occ_0', 'occ_1', 'occ_2', 'occ_3', 'occ_4', 'occ_5', 'occ_6', 'occ_7', 'occ_8', 'occ_9', 'occ_10', 'occ_11', 'occ_12', 'occ_13', 'occ_14', 'occ_15', 'occ_16', 'occ_17', 'occ_18', 'occ_19', 'occ_20']\n",
      "User feature dtypes:\n",
      "user_id    float64\n",
      "gender     float64\n",
      "age_1      float64\n",
      "age_18     float64\n",
      "age_25     float64\n",
      "age_35     float64\n",
      "age_45     float64\n",
      "age_50     float64\n",
      "age_56     float64\n",
      "occ_0      float64\n",
      "occ_1      float64\n",
      "occ_2      float64\n",
      "occ_3      float64\n",
      "occ_4      float64\n",
      "occ_5      float64\n",
      "occ_6      float64\n",
      "occ_7      float64\n",
      "occ_8      float64\n",
      "occ_9      float64\n",
      "occ_10     float64\n",
      "occ_11     float64\n",
      "occ_12     float64\n",
      "occ_13     float64\n",
      "occ_14     float64\n",
      "occ_15     float64\n",
      "occ_16     float64\n",
      "occ_17     float64\n",
      "occ_18     float64\n",
      "occ_19     float64\n",
      "occ_20     float64\n",
      "dtype: object\n",
      "User feature dimension: 29\n",
      "Using device: cpu\n",
      "Preparing movie features with sentence transformers...\n",
      "Loading sentence transformer model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding movie titles...\n",
      "Encoding movie genres...\n",
      "Title embeddings shape: torch.Size([3883, 384])\n",
      "Genre embeddings shape: torch.Size([3883, 384])\n",
      "Combined movie embeddings shape: torch.Size([3883, 768])\n",
      "Normalizing movie embeddings...\n",
      "Original embeddings - mean: 0.0010, std: 0.0510\n",
      "Normalized embeddings - mean: 0.0007, std: 0.0361\n",
      "Movie feature dimension: 768\n",
      "\n",
      "Feature preparation complete!\n",
      "User feature dimension: 29\n",
      "Movie feature dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Initialize feature processor and prepare features\n",
    "print(\"Preparing user and movie features...\")\n",
    "\n",
    "# Initialize feature processor\n",
    "feature_processor = FeatureProcessor()\n",
    "\n",
    "# Prepare user features\n",
    "user_features_df = feature_processor.prepare_user_features(users)\n",
    "\n",
    "# Prepare movie features  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "movie_embeddings = feature_processor.prepare_movie_features(movies, device=device)\n",
    "\n",
    "print(f\"\\nFeature preparation complete!\")\n",
    "print(f\"User feature dimension: {feature_processor.user_feature_dim}\")\n",
    "print(f\"Movie feature dimension: {feature_processor.movie_feature_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc83867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 97208 entries, 799 to 998118\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   user_id    97208 non-null  int64\n",
      " 1   movie_id   97208 non-null  int64\n",
      " 2   rating     97208 non-null  int64\n",
      " 3   timestamp  97208 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f538cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rank_latest'] = ratings.groupby(['user_id'])['timestamp'] \\\n",
    "                                .rank(method = 'first',ascending=False)\n",
    "\n",
    "train_ratings = ratings[ratings['rank_latest'].isin([1,2])]\n",
    "validation_ratings = ratings[ratings['rank_latest'] == 1]\n",
    "test_ratings = ratings[ratings['rank_latest'] == 2]\n",
    "\n",
    "# drop columns that we no Longer need \n",
    "train_ratings = train_ratings[['user_id', 'movie_id', 'rating']]\n",
    "test_ratings = test_ratings[['user_id','movie_id','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228a99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings['user_id'].max()+1\n",
    "num_items = ratings['movie_id'].max()+1\n",
    "\n",
    "all_movieIds = ratings['movie_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df34dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "candidate_gen = CandidateGenerator(ratings, movies, all_movieIds)\n",
    "\n",
    "def generate_candidates(user_id, method=\"hybrid\", num_candidates=100):\n",
    "    \"\"\"Backward compatible interface\"\"\"\n",
    "    return candidate_gen.generate_candidates(user_id, method, num_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a555y7g5r7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing candidates for 604 validation users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec3871da89b49a69c18c1830f40a5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing candidates:   0%|          | 0/604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed candidates for 604 users\n"
     ]
    }
   ],
   "source": [
    "# Precompute validation candidates for faster validation\n",
    "def precompute_validation_candidates(validation_ratings, candidate_method=\"hybrid\", num_candidates=100):\n",
    "    \"\"\"\n",
    "    Precompute candidates for all validation users to speed up validation\n",
    "    \n",
    "    Returns:\n",
    "        dict: {user_id: [candidate_items]}\n",
    "    \"\"\"\n",
    "    validation_users = validation_ratings['user_id'].unique()\n",
    "    precomputed_candidates = {}\n",
    "    \n",
    "    print(f\"Precomputing candidates for {len(validation_users)} validation users...\")\n",
    "    \n",
    "    for user_id in tqdm(validation_users, desc=\"Precomputing candidates\"):\n",
    "        candidates = generate_candidates(user_id, method=candidate_method, num_candidates=num_candidates)\n",
    "        precomputed_candidates[user_id] = candidates\n",
    "    \n",
    "    print(f\"Precomputed candidates for {len(precomputed_candidates)} users\")\n",
    "    return precomputed_candidates\n",
    "\n",
    "# Precompute candidates before training\n",
    "validation_candidates = precompute_validation_candidates(validation_ratings, candidate_method=\"hybrid\", num_candidates=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd673a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Training with UNIQUE_PER_USER sampling + HYBRID negatives\n",
      "======================================================================\n",
      "Generating training dataset with hybrid negative sampling\n",
      "Sampling strategy: unique_per_user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   0%|          | 0/604 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users: 100%|██████████| 604/604 [00:02<00:00, 244.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6040 samples (1208 positive, 4832 negative)\n",
      "Negative-to-positive ratio: 4.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe71516557744138834602c4da2250ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.44037729501724243, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.4290313124656677, Rank=11/101\n",
      "User 1878, Movie 1920: Score=0.4386969208717346, Rank=34/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.100\n",
      "Mean Rank: 40.8\n",
      "MRR: 0.044\n",
      "Epoch 1/30\n",
      "  Training Loss: 0.6122\n",
      "  Hit Ratio @ 10: 0.100\n",
      "  Mean Rank: 40.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ff160c696046fcaa14ec7dfe96c481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.3369556963443756, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.29546254873275757, Rank=32/101\n",
      "User 1878, Movie 1920: Score=0.31023266911506653, Rank=35/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.150\n",
      "Mean Rank: 35.1\n",
      "MRR: 0.071\n",
      "Epoch 2/30\n",
      "  Training Loss: 0.4681\n",
      "  Hit Ratio @ 10: 0.150\n",
      "  Mean Rank: 35.1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfba582fe834d79a0665899f6b42340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.3451530635356903, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.2943115532398224, Rank=59/101\n",
      "User 1878, Movie 1920: Score=0.3256585896015167, Rank=47/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 40.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.250\n",
      "Mean Rank: 26.0\n",
      "MRR: 0.099\n",
      "Epoch 3/30\n",
      "  Training Loss: 0.4152\n",
      "  Hit Ratio @ 10: 0.250\n",
      "  Mean Rank: 26.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f40f9e2d9d4499b873e1ad57dfb3aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.3989992141723633, Rank=13/101\n",
      "User 3912, Movie 318: Score=0.25579217076301575, Rank=70/101\n",
      "User 1878, Movie 1920: Score=0.40366479754447937, Rank=34/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 22.0\n",
      "MRR: 0.111\n",
      "Epoch 4/30\n",
      "  Training Loss: 0.3771\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 22.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cc6abce1854e44a01dceb24e72b86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 5/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.40701091289520264, Rank=19/101\n",
      "User 3912, Movie 318: Score=0.08202077448368073, Rank=81/101\n",
      "User 1878, Movie 1920: Score=0.4544217884540558, Rank=11/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.400\n",
      "Mean Rank: 20.6\n",
      "MRR: 0.118\n",
      "Epoch 5/30\n",
      "  Training Loss: 0.3672\n",
      "  Hit Ratio @ 10: 0.400\n",
      "  Mean Rank: 20.6\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef45d6926494379945f7939f15e4dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 6/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 40%|████      | 8/20 [00:00<00:00, 39.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.49116724729537964, Rank=11/101\n",
      "User 3912, Movie 318: Score=0.1678314507007599, Rank=55/101\n",
      "User 1878, Movie 1920: Score=0.48056796193122864, Rank=15/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 40.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.300\n",
      "Mean Rank: 19.8\n",
      "MRR: 0.183\n",
      "Epoch 6/30\n",
      "  Training Loss: 0.3527\n",
      "  Hit Ratio @ 10: 0.300\n",
      "  Mean Rank: 19.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d779a3eb5a304c12b4c0aed9f05e8886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 7/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5256261229515076, Rank=11/101\n",
      "User 3912, Movie 318: Score=0.1539817452430725, Rank=60/101\n",
      "User 1878, Movie 1920: Score=0.5475562214851379, Rank=3/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 40.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.350\n",
      "Mean Rank: 18.5\n",
      "MRR: 0.216\n",
      "Epoch 7/30\n",
      "  Training Loss: 0.3428\n",
      "  Hit Ratio @ 10: 0.350\n",
      "  Mean Rank: 18.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51c76cc74c44834861536108f21f853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 8/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5555854439735413, Rank=13/101\n",
      "User 3912, Movie 318: Score=0.06617240607738495, Rank=67/101\n",
      "User 1878, Movie 1920: Score=0.5992380976676941, Rank=4/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 16.9\n",
      "MRR: 0.208\n",
      "Epoch 8/30\n",
      "  Training Loss: 0.3382\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 16.9\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199d87a6b5df4791a2307e810d4d78a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 9/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5748283863067627, Rank=14/101\n",
      "User 3912, Movie 318: Score=0.054387327283620834, Rank=67/101\n",
      "User 1878, Movie 1920: Score=0.6536611914634705, Rank=3/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 17.4\n",
      "MRR: 0.187\n",
      "Epoch 9/30\n",
      "  Training Loss: 0.3197\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 17.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0762e9e4b054e0bbee016a0b30d077e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 10/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5986843109130859, Rank=17/101\n",
      "User 3912, Movie 318: Score=0.12015338987112045, Rank=54/101\n",
      "User 1878, Movie 1920: Score=0.6441234946250916, Rank=6/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 17.0\n",
      "MRR: 0.218\n",
      "Epoch 10/30\n",
      "  Training Loss: 0.3159\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 17.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9c5bf13cd44ac08c96b916c7df9f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 11/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6596648693084717, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.08510959148406982, Rank=57/101\n",
      "User 1878, Movie 1920: Score=0.7656408548355103, Rank=2/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 17.0\n",
      "MRR: 0.216\n",
      "Epoch 11/30\n",
      "  Training Loss: 0.3090\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 17.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3ee18709b34397bec097afa266b002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 12/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7018331289291382, Rank=7/101\n",
      "User 3912, Movie 318: Score=0.10382744669914246, Rank=53/101\n",
      "User 1878, Movie 1920: Score=0.7575283050537109, Rank=2/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 16.5\n",
      "MRR: 0.197\n",
      "Epoch 12/30\n",
      "  Training Loss: 0.2955\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 16.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc4ee189d1b491d92099e5363afb40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 13/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 40.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6593433618545532, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.07652763277292252, Rank=57/101\n",
      "User 1878, Movie 1920: Score=0.7732664346694946, Rank=2/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 16.2\n",
      "MRR: 0.208\n",
      "Epoch 13/30\n",
      "  Training Loss: 0.2915\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 16.2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c920ddc1562449a5b92130bfc0d30c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 14/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.72383052110672, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.1392294317483902, Rank=46/101\n",
      "User 1878, Movie 1920: Score=0.7765734195709229, Rank=3/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 18.1\n",
      "MRR: 0.136\n",
      "Epoch 14/30\n",
      "  Training Loss: 0.2784\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 18.1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8908f18b11fc40daa8c55c1cd6f77fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 15/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7040122151374817, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.09388899803161621, Rank=51/101\n",
      "User 1878, Movie 1920: Score=0.7757425308227539, Rank=6/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.350\n",
      "Mean Rank: 18.1\n",
      "MRR: 0.134\n",
      "Epoch 15/30\n",
      "  Training Loss: 0.2815\n",
      "  Hit Ratio @ 10: 0.350\n",
      "  Mean Rank: 18.1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61466b925175437b9ab74e22b427dec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 16/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6357342004776001, Rank=13/101\n",
      "User 3912, Movie 318: Score=0.0536651685833931, Rank=65/101\n",
      "User 1878, Movie 1920: Score=0.8284608721733093, Rank=4/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 17.4\n",
      "MRR: 0.224\n",
      "Epoch 16/30\n",
      "  Training Loss: 0.2835\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 17.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee6917f136146faa7fd467b190cc0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 17/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.44208282232284546, Rank=18/101\n",
      "User 3912, Movie 318: Score=0.05584586411714554, Rank=65/101\n",
      "User 1878, Movie 1920: Score=0.8114766478538513, Rank=4/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 15.6\n",
      "MRR: 0.195\n",
      "Epoch 17/30\n",
      "  Training Loss: 0.2649\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 15.6\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897b282a14d54bce9dd672d6985d3a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 18/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.662321925163269, Rank=16/101\n",
      "User 3912, Movie 318: Score=0.0686386302113533, Rank=59/101\n",
      "User 1878, Movie 1920: Score=0.888702929019928, Rank=2/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 17.5\n",
      "MRR: 0.159\n",
      "Epoch 18/30\n",
      "  Training Loss: 0.2592\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 17.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd50601ceef4ae4b7290ec0a3903268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 19/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5656970739364624, Rank=20/101\n",
      "User 3912, Movie 318: Score=0.06469589471817017, Rank=55/101\n",
      "User 1878, Movie 1920: Score=0.9249476194381714, Rank=2/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.550\n",
      "Mean Rank: 15.4\n",
      "MRR: 0.164\n",
      "Epoch 19/30\n",
      "  Training Loss: 0.2554\n",
      "  Hit Ratio @ 10: 0.550\n",
      "  Mean Rank: 15.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4764b0904974bc7bfa551a6027d0483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 20/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5472177863121033, Rank=19/101\n",
      "User 3912, Movie 318: Score=0.055226102471351624, Rank=56/101\n",
      "User 1878, Movie 1920: Score=0.8076252341270447, Rank=4/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 17.8\n",
      "MRR: 0.129\n",
      "Epoch 20/30\n",
      "  Training Loss: 0.2516\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 17.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103cf270884a431d87baa924ff0880fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 21/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.8113176226615906, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.07552210986614227, Rank=53/101\n",
      "User 1878, Movie 1920: Score=0.9106428623199463, Rank=3/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 43.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.550\n",
      "Mean Rank: 15.8\n",
      "MRR: 0.144\n",
      "Epoch 21/30\n",
      "  Training Loss: 0.2476\n",
      "  Hit Ratio @ 10: 0.550\n",
      "  Mean Rank: 15.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32b73ffb33542b9a9ccb16826e60cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 22/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.4080292582511902, Rank=21/101\n",
      "User 3912, Movie 318: Score=0.07548444718122482, Rank=55/101\n",
      "User 1878, Movie 1920: Score=0.8616580963134766, Rank=6/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 16.7\n",
      "MRR: 0.114\n",
      "Epoch 22/30\n",
      "  Training Loss: 0.2456\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 16.7\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead32563b31543b69effdbba3d78b5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 23/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.3492794334888458, Rank=23/101\n",
      "User 3912, Movie 318: Score=0.03836265206336975, Rank=62/101\n",
      "User 1878, Movie 1920: Score=0.9150837063789368, Rank=5/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 41.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.550\n",
      "Mean Rank: 15.8\n",
      "MRR: 0.138\n",
      "Epoch 23/30\n",
      "  Training Loss: 0.2388\n",
      "  Hit Ratio @ 10: 0.550\n",
      "  Mean Rank: 15.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ff4aa1b76c4ae7831c2cace80cd98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 24/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6809270977973938, Rank=14/101\n",
      "User 3912, Movie 318: Score=0.05287398397922516, Rank=61/101\n",
      "User 1878, Movie 1920: Score=0.9136427044868469, Rank=2/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.600\n",
      "Mean Rank: 16.8\n",
      "MRR: 0.120\n",
      "Epoch 24/30\n",
      "  Training Loss: 0.2370\n",
      "  Hit Ratio @ 10: 0.600\n",
      "  Mean Rank: 16.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a51424afeb40e889f5c6419c653e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 25/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6502379775047302, Rank=13/101\n",
      "User 3912, Movie 318: Score=0.04443759471178055, Rank=57/101\n",
      "User 1878, Movie 1920: Score=0.9467769861221313, Rank=3/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 40.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.550\n",
      "Mean Rank: 16.0\n",
      "MRR: 0.122\n",
      "Epoch 25/30\n",
      "  Training Loss: 0.2268\n",
      "  Hit Ratio @ 10: 0.550\n",
      "  Mean Rank: 16.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5892fa1e273b44478821f0f4cf775d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 26/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.865036129951477, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.06536994874477386, Rank=53/101\n",
      "User 1878, Movie 1920: Score=0.9431481957435608, Rank=4/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 15.8\n",
      "MRR: 0.132\n",
      "Epoch 26/30\n",
      "  Training Loss: 0.2257\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 15.8\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d64b6892614421a8d751d199b162bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 27/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5905780792236328, Rank=18/101\n",
      "User 3912, Movie 318: Score=0.04874792322516441, Rank=55/101\n",
      "User 1878, Movie 1920: Score=0.9399387836456299, Rank=3/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 17.0\n",
      "MRR: 0.127\n",
      "Epoch 27/30\n",
      "  Training Loss: 0.2361\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 17.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0b0a0799ee44668ef7718d7763f857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 28/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.3882049024105072, Rank=21/101\n",
      "User 3912, Movie 318: Score=0.06110570579767227, Rank=56/101\n",
      "User 1878, Movie 1920: Score=0.9504784345626831, Rank=2/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 16.2\n",
      "MRR: 0.140\n",
      "Epoch 28/30\n",
      "  Training Loss: 0.2282\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 16.2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9873d08adb314d45993fa70fab09ae99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 29/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.8466307520866394, Rank=14/101\n",
      "User 3912, Movie 318: Score=0.057282112538814545, Rank=54/101\n",
      "User 1878, Movie 1920: Score=0.9574284553527832, Rank=2/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 42.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.350\n",
      "Mean Rank: 17.5\n",
      "MRR: 0.121\n",
      "Epoch 29/30\n",
      "  Training Loss: 0.2257\n",
      "  Hit Ratio @ 10: 0.350\n",
      "  Mean Rank: 17.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ba6b68c0a64b77a012fc81abd9955d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 30/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.827118456363678, Rank=15/101\n",
      "User 3912, Movie 318: Score=0.05971883237361908, Rank=56/101\n",
      "User 1878, Movie 1920: Score=0.8863867521286011, Rank=6/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 40.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.400\n",
      "Mean Rank: 17.3\n",
      "MRR: 0.113\n",
      "Epoch 30/30\n",
      "  Training Loss: 0.2203\n",
      "  Hit Ratio @ 10: 0.400\n",
      "  Mean Rank: 17.3\n",
      "--------------------------------------------------\n",
      "Training with unique_per_user_hybrid completed!\n",
      "Final Hit Ratio @ 10: 0.400\n",
      "Final Mean Rank: 17.3\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "======================================================================\n",
      "unique_per_user_hybrid         | Hit Ratio: 0.400 | Mean Rank: 17.3\n",
      "\n",
      "All experiments completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_strategies = [\n",
    "    (\"unique_per_user\", \"hybrid\"),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for sampling_strategy, neg_method in sampling_strategies:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training with {sampling_strategy.upper()} sampling + {neg_method.upper()} negatives\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Create optimized model with CORRECT feature dimensions\n",
    "    model = NCF(\n",
    "        user_feature_dim=feature_processor.user_feature_dim,\n",
    "        movie_feature_dim=feature_processor.movie_feature_dim,\n",
    "        ratings=train_ratings, \n",
    "        feature_processor=feature_processor,\n",
    "        candidate_generator=candidate_gen,\n",
    "        negative_method=neg_method, \n",
    "        sampling_strategy=sampling_strategy\n",
    "    )\n",
    "\n",
    "    # Set up training parameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    dataloader = model.get_dataloader(batch_size=512, num_workers=4, num_negatives=4)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 30\n",
    "    \n",
    "    epoch_results = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in tqdm(dataloader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            # Move batch to device\n",
    "            user_input, item_input, labels = [x.to(device) for x in batch]\n",
    "            batch_device = (user_input, item_input, labels)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass and compute loss\n",
    "            loss = model.compute_loss(batch_device)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            hit_ratio, mrr, mean_rank = validate_model_with_features(\n",
    "                model, validation_ratings, validation_candidates, device, \n",
    "                total_users_to_test=20, k=10\n",
    "            )\n",
    "        \n",
    "        epoch_results.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_loss,\n",
    "            'hit_ratio': hit_ratio,\n",
    "            'mean_rank': mean_rank\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Training Loss: {avg_loss:.4f}\")\n",
    "        print(f\"  Hit Ratio @ 10: {hit_ratio:.3f}\")\n",
    "        print(f\"  Mean Rank: {mean_rank:.1f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Store results\n",
    "    strategy_name = f\"{sampling_strategy}_{neg_method}\"\n",
    "    results[strategy_name] = epoch_results\n",
    "    \n",
    "    print(f\"Training with {strategy_name} completed!\")\n",
    "    print(f\"Final Hit Ratio @ 10: {hit_ratio:.3f}\")\n",
    "    print(f\"Final Mean Rank: {mean_rank:.1f}\")\n",
    "\n",
    "# Summary of results\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for strategy_name, epoch_results in results.items():\n",
    "    final_result = epoch_results[-1]\n",
    "    print(f\"{strategy_name:30} | Hit Ratio: {final_result['hit_ratio']:.3f} | Mean Rank: {final_result['mean_rank']:.1f}\")\n",
    "\n",
    "print(\"\\nAll experiments completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d42bd8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL SAVE AND LOAD DEMONSTRATION\n",
      "================================================================================\n",
      "\n",
      "1. SAVING MODEL\n",
      "--------------------------------------------------\n",
      "Model weights saved to models/ncf_trained_model.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL SAVE AND LOAD DEMONSTRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = \"models/ncf_trained_model.pth\"\n",
    "print(f\"\\n1. SAVING MODEL\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "model.save_weights(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9638ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model performance on test set...\n",
      "Precomputing candidates for 604 test users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5c0041e06d4ea29962838438cbf895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing test candidates:   0%|          | 0/604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:00<00:01, 42.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 2898, Movie 2502: Score=0.9365142583847046, Rank=3/101\n",
      "User 4689, Movie 3793: Score=0.8687427639961243, Rank=5/101\n",
      "User 3138, Movie 1580: Score=0.14046785235404968, Rank=34/101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total test cases: 50\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 50\n",
      "Hit Ratio @ 10: 0.540\n",
      "Mean Rank: 16.0\n",
      "MRR: 0.190\n",
      "TEST SET RESULTS:\n",
      "Hit Ratio @ 10: 0.540\n",
      "Mean Rank: 16.0\n",
      "MRR: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing model performance on test set...\")\n",
    "\n",
    "def precompute_test_candidates(test_ratings, candidate_method=\"hybrid\", num_candidates=100):\n",
    "    test_users = test_ratings['user_id'].unique()\n",
    "    precomputed_candidates = {}\n",
    "    \n",
    "    print(f\"Precomputing candidates for {len(test_users)} test users...\")\n",
    "    \n",
    "    for user_id in tqdm(test_users, desc=\"Precomputing test candidates\"):\n",
    "        candidates = generate_candidates(user_id, method=candidate_method, num_candidates=num_candidates)\n",
    "        precomputed_candidates[user_id] = candidates\n",
    "    \n",
    "    return precomputed_candidates\n",
    "\n",
    "test_candidates = precompute_test_candidates(test_ratings, candidate_method=\"hybrid\", num_candidates=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(f\"Evaluating on test set...\")\n",
    "    test_hit_ratio, test_mrr, test_mean_rank = validate_model_with_features(\n",
    "        model, test_ratings, test_candidates, device, \n",
    "        total_users_to_test=50, k=10\n",
    "    )\n",
    "\n",
    "print(f\"TEST SET RESULTS:\")\n",
    "print(f\"Hit Ratio @ 10: {test_hit_ratio:.3f}\")\n",
    "print(f\"Mean Rank: {test_mean_rank:.1f}\")\n",
    "print(f\"MRR: {test_mrr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "911dac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. LOADING COMPLETE MODEL (CLASS METHOD)\n",
      "--------------------------------------------------\n",
      "Complete model loaded successfully from models/ncf_trained_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate loading complete model using class method\n",
    "print(f\"\\n4. LOADING COMPLETE MODEL (CLASS METHOD)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "loaded_model = NCF.load_model(\n",
    "    filepath=model_save_path,\n",
    "    ratings=train_ratings,\n",
    "    feature_processor=feature_processor,\n",
    "    candidate_generator=candidate_gen\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc89c335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cold Start Recommender initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the cold start recommender with the trained model\n",
    "cold_start_recommender = ColdStartRecommender(\n",
    "    trained_model=loaded_model,\n",
    "    feature_processor=feature_processor,\n",
    "    candidate_generator=candidate_gen,\n",
    "    movies_df=movies\n",
    ")\n",
    "\n",
    "print(\"Cold Start Recommender initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "736eaa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COLD START RECOMMENDATION SYSTEM DEMONSTRATION\n",
      "================================================================================\n",
      "\n",
      "1. PURE COLD START SCENARIO\n",
      "--------------------------------------------------\n",
      "New User Demographics: {'gender': 'M', 'age': 25, 'occupation': 4}\n",
      "\n",
      "Top 10 Cold Start Recommendations:\n",
      " 1. Life Is Beautiful (La Vita � bella) (1997)         (Score: 0.997)\n",
      " 2. Sling Blade (1996)                                 (Score: 0.992)\n",
      " 3. Maltese Falcon, The (1941)                         (Score: 0.989)\n",
      " 4. Platoon (1986)                                     (Score: 0.988)\n",
      " 5. Doctor Zhivago (1965)                              (Score: 0.988)\n",
      " 6. Rebel Without a Cause (1955)                       (Score: 0.985)\n",
      " 7. Vertigo (1958)                                     (Score: 0.983)\n",
      " 8. Akira (1988)                                       (Score: 0.974)\n",
      " 9. Fisher King, The (1991)                            (Score: 0.970)\n",
      "10. Third Man, The (1949)                              (Score: 0.968)\n",
      "\n",
      "\n",
      "2. ONBOARDING MOVIES FOR RATING COLLECTION\n",
      "--------------------------------------------------\n",
      "Movies to show new user for initial ratings (diverse genres):\n",
      "1. American Beauty (1999)                   | Genres: Comedy|Drama\n",
      "2. American Beauty (1999)                   | Genres: Comedy|Drama\n",
      "3. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "4. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "5. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "6. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "7. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "8. Star Wars: Episode IV - A New Hope (1977) | Genres: Action|Adventure|Fantasy|Sci-Fi\n",
      "\n",
      "\n",
      "3. WARM COLD START SCENARIO\n",
      "--------------------------------------------------\n",
      "User's initial ratings:\n",
      "  American Beauty (1999)                             - Rating: 5/5\n",
      "  American Beauty (1999)                             - Rating: 4/5\n",
      "  Star Wars: Episode VI - Return of the Jedi (1983)  - Rating: 2/5\n",
      "  Star Wars: Episode VI - Return of the Jedi (1983)  - Rating: 4/5\n",
      "\n",
      "Top 10 Recommendations after initial ratings:\n",
      " 1. Life Is Beautiful (La Vita � bella) (1997)         (Score: 0.997)\n",
      " 2. Rob Roy (1995)                                     (Score: 0.997)\n",
      " 3. Manhattan (1979)                                   (Score: 0.985)\n",
      " 4. Singles (1992)                                     (Score: 0.983)\n",
      " 5. Wings of Desire (Der Himmel �ber Berlin) (1987)    (Score: 0.980)\n",
      " 6. Eat Drink Man Woman (1994)                         (Score: 0.977)\n",
      " 7. Reality Bites (1994)                               (Score: 0.973)\n",
      " 8. Pretty in Pink (1986)                              (Score: 0.971)\n",
      " 9. Fisher King, The (1991)                            (Score: 0.970)\n",
      "10. Slingshot, The (K�disbellan ) (1993)               (Score: 0.951)\n",
      "\n",
      "\n",
      "4. COMPARISON: Different User Demographics\n",
      "--------------------------------------------------\n",
      "Different User Demographics: {'gender': 'F', 'age': 45, 'occupation': 0}\n",
      "\n",
      "Top 5 Recommendations for different demographic:\n",
      "1. Life Is Beautiful (La Vita � bella) (1997)         (Score: 0.995)\n",
      "2. Mission to Mars (2000)                             (Score: 0.983)\n",
      "3. Shanghai Noon (2000)                               (Score: 0.977)\n",
      "4. Grumpy Old Men (1993)                              (Score: 0.976)\n",
      "5. Grumpier Old Men (1995)                            (Score: 0.972)\n",
      "\n",
      "================================================================================\n",
      "Cold Start Recommendation Demonstration Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# DEMONSTRATION: Cold Start Recommendation Examples\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COLD START RECOMMENDATION SYSTEM DEMONSTRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Example 1: Pure Cold Start - New user with only demographics\n",
    "print(\"\\n1. PURE COLD START SCENARIO\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "new_user_demographics = {\n",
    "    'gender': 'M',     # Male\n",
    "    'age': 25,         # 25 years old  \n",
    "    'occupation': 4    # College/grad student (based on MovieLens occupation codes)\n",
    "}\n",
    "\n",
    "print(f\"New User Demographics: {new_user_demographics}\")\n",
    "\n",
    "# Get recommendations without any ratings\n",
    "cold_start_recommendations = cold_start_recommender.recommend_for_new_user(\n",
    "    user_demographics=new_user_demographics,\n",
    "    user_ratings=None,  # No ratings yet\n",
    "    num_recommendations=10\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 10 Cold Start Recommendations:\")\n",
    "for i, (movie_id, title, score) in enumerate(cold_start_recommendations, 1):\n",
    "    print(f\"{i:2d}. {title:<50} (Score: {score:.3f})\")\n",
    "\n",
    "# Example 2: Get onboarding movies for initial rating collection\n",
    "print(f\"\\n\\n2. ONBOARDING MOVIES FOR RATING COLLECTION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "onboarding_movies = cold_start_recommender.get_onboarding_movies(num_movies=8)\n",
    "\n",
    "print(\"Movies to show new user for initial ratings (diverse genres):\")\n",
    "for i, (movie_id, title, genres) in enumerate(onboarding_movies, 1):\n",
    "    print(f\"{i}. {title:<40} | Genres: {genres}\")\n",
    "\n",
    "# Example 3: Warm Cold Start - User has provided some initial ratings\n",
    "print(f\"\\n\\n3. WARM COLD START SCENARIO\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Simulate user rating some of the onboarding movies\n",
    "initial_ratings = [\n",
    "    (onboarding_movies[0][0], 5),  # Loved the first movie\n",
    "    (onboarding_movies[1][0], 4),  # Liked the second movie\n",
    "    (onboarding_movies[2][0], 2),  # Didn't like the third movie\n",
    "    (onboarding_movies[3][0], 4),  # Liked the fourth movie\n",
    "]\n",
    "\n",
    "print(\"User's initial ratings:\")\n",
    "for movie_id, rating in initial_ratings:\n",
    "    movie_title = movies[movies['movie_id'] == movie_id]['title'].iloc[0]\n",
    "    print(f\"  {movie_title:<50} - Rating: {rating}/5\")\n",
    "\n",
    "# Get improved recommendations based on initial ratings\n",
    "warm_recommendations = cold_start_recommender.recommend_for_new_user(\n",
    "    user_demographics=new_user_demographics,\n",
    "    user_ratings=initial_ratings,\n",
    "    num_recommendations=10\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 10 Recommendations after initial ratings:\")\n",
    "for i, (movie_id, title, score) in enumerate(warm_recommendations, 1):\n",
    "    print(f\"{i:2d}. {title:<50} (Score: {score:.3f})\")\n",
    "\n",
    "print(f\"\\n\\n4. COMPARISON: Different User Demographics\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Example with different demographics\n",
    "female_user_demographics = {\n",
    "    'gender': 'F',     # Female\n",
    "    'age': 45,         # 45 years old\n",
    "    'occupation': 0    # Other/not specified\n",
    "}\n",
    "\n",
    "print(f\"Different User Demographics: {female_user_demographics}\")\n",
    "\n",
    "female_recommendations = cold_start_recommender.recommend_for_new_user(\n",
    "    user_demographics=female_user_demographics,\n",
    "    user_ratings=None,\n",
    "    num_recommendations=5\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 5 Recommendations for different demographic:\")\n",
    "for i, (movie_id, title, score) in enumerate(female_recommendations, 1):\n",
    "    print(f\"{i}. {title:<50} (Score: {score:.3f})\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Cold Start Recommendation Demonstration Complete!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
