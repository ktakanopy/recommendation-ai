{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dab989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f5c0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82120/4112843497.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_csv(\"../two_towers/data/ml-1m/ratings.dat\", sep=\"::\", header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp\n",
      "0        1      1193       5  978300760\n",
      "1        1       661       3  978302109\n",
      "2        1       914       3  978301968\n",
      "3        1      3408       4  978300275\n",
      "4        1      2355       5  978824291\n",
      "   movie_id                               title                        genres\n",
      "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4         5  Father of the Bride Part II (1995)                        Comedy\n",
      "   user_id gender  age  occupation zip_code\n",
      "0        1      F    1          10    48067\n",
      "1        2      M   56          16    70072\n",
      "2        3      M   25          15    55117\n",
      "3        4      M   45           7    02460\n",
      "4        5      M   25          20    55455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82120/4112843497.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies = pd.read_csv(\"../two_towers/data/ml-1m/movies.dat\", sep=\"::\", header=None)\n",
      "/tmp/ipykernel_82120/4112843497.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users = pd.read_csv(\"../two_towers/data/ml-1m/users.dat\", sep=\"::\", header=None)\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"../two_towers/data/ml-1m/ratings.dat\", sep=\"::\", header=None)\n",
    "ratings.columns = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "\n",
    "movies = pd.read_csv(\"../two_towers/data/ml-1m/movies.dat\", sep=\"::\", header=None)\n",
    "movies.columns = [\"movie_id\", \"title\", \"genres\"]\n",
    "\n",
    "users = pd.read_csv(\"../two_towers/data/ml-1m/users.dat\", sep=\"::\", header=None)\n",
    "users.columns = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zip_code\"]\n",
    "\n",
    "print(ratings.head())\n",
    "print(movies.head())\n",
    "print(users.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a92d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604\n",
      "     user_id  movie_id  rating  timestamp\n",
      "799       10      2622       5  978228212\n",
      "800       10       648       4  978224925\n",
      "801       10      2628       3  978228408\n",
      "802       10      3358       5  978226378\n",
      "803       10      3359       3  978227125\n"
     ]
    }
   ],
   "source": [
    "rand_userIds = np.random.choice(ratings['user_id'].unique(),\n",
    "                               size=int(len(ratings['user_id'].unique())*0.1),\n",
    "                               replace=False)\n",
    "print(len(rand_userIds))\n",
    "ratings = ratings.loc[ratings['user_id'].isin(rand_userIds)]\n",
    "\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d4f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Feature preprocessing functions\n",
    "class FeatureProcessor:\n",
    "    def __init__(self):\n",
    "        self.user_encoders = {}\n",
    "        self.movie_encoders = {}\n",
    "        self.sentence_model = None\n",
    "        self.user_features_cache = {}\n",
    "        self.movie_features_cache = {}\n",
    "        \n",
    "    def prepare_user_features(self, users_df):\n",
    "        \"\"\"Prepare user features: gender, age, occupation one-hot encoding\"\"\"\n",
    "        print(\"Preparing user features...\")\n",
    "        \n",
    "        # Gender encoding (M=1, F=0)\n",
    "        gender_encoded = (users_df['gender'] == 'M').astype(float)\n",
    "        \n",
    "        # Age one-hot encoding (7 categories: 1, 18, 25, 35, 45, 50, 56)\n",
    "        age_onehot = pd.get_dummies(users_df['age'], prefix='age').astype(float)\n",
    "        \n",
    "        # Occupation one-hot encoding (0-20)\n",
    "        occupation_onehot = pd.get_dummies(users_df['occupation'], prefix='occ').astype(float)\n",
    "        \n",
    "        # Combine all user features into a single DataFrame\n",
    "        feature_columns = ['user_id']\n",
    "        feature_data = [users_df['user_id'].values]\n",
    "        \n",
    "        # Add gender\n",
    "        feature_columns.append('gender')\n",
    "        feature_data.append(gender_encoded.values)\n",
    "        \n",
    "        # Add age features\n",
    "        for col in age_onehot.columns:\n",
    "            feature_columns.append(col)\n",
    "            feature_data.append(age_onehot[col].values)\n",
    "        \n",
    "        # Add occupation features\n",
    "        for col in occupation_onehot.columns:\n",
    "            feature_columns.append(col)\n",
    "            feature_data.append(occupation_onehot[col].values)\n",
    "        \n",
    "        # Create feature matrix\n",
    "        feature_matrix = np.column_stack(feature_data)\n",
    "        user_features = pd.DataFrame(feature_matrix, columns=feature_columns)\n",
    "        \n",
    "        # Ensure all feature columns (except user_id) are float\n",
    "        for col in user_features.columns:\n",
    "            if col != 'user_id':\n",
    "                user_features[col] = user_features[col].astype(float)\n",
    "        \n",
    "        print(f\"User features shape: {user_features.shape}\")\n",
    "        print(f\"User feature columns: {list(user_features.columns)}\")\n",
    "        print(f\"User feature dtypes:\\n{user_features.dtypes}\")\n",
    "        \n",
    "        # Cache features for quick lookup (keep on CPU)\n",
    "        for _, row in user_features.iterrows():\n",
    "            user_id = int(row['user_id'])\n",
    "            # Get feature values excluding user_id and convert to numpy array\n",
    "            feature_values = row.drop('user_id').values.astype(np.float32)\n",
    "            features = torch.tensor(feature_values, dtype=torch.float32)\n",
    "            self.user_features_cache[user_id] = features\n",
    "            \n",
    "        self.user_feature_dim = len(user_features.columns) - 1  # Exclude user_id\n",
    "        print(f\"User feature dimension: {self.user_feature_dim}\")\n",
    "        return user_features\n",
    "    \n",
    "    def prepare_movie_features(self, movies_df, device='cpu'):\n",
    "        \"\"\"Prepare movie features using sentence transformers for title and genres\"\"\"\n",
    "        print(\"Preparing movie features with sentence transformers...\")\n",
    "        \n",
    "        # Initialize sentence transformer\n",
    "        if self.sentence_model is None:\n",
    "            print(\"Loading sentence transformer model...\")\n",
    "            self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "        \n",
    "        # Encode movie titles\n",
    "        print(\"Encoding movie titles...\")\n",
    "        titles = movies_df['title'].tolist()\n",
    "        title_embeddings = self.sentence_model.encode(\n",
    "            titles, convert_to_tensor=True, device=device, batch_size=64\n",
    "        )\n",
    "        \n",
    "        # Process genres and encode them\n",
    "        print(\"Encoding movie genres...\")\n",
    "        genre_texts = []\n",
    "        for genres_str in movies_df['genres']:\n",
    "            # Convert pipe-separated genres to readable text\n",
    "            genres_list = genres_str.split('|')\n",
    "            genre_text = ' '.join(genres_list).replace(\"Children's\", \"Children\")\n",
    "            genre_texts.append(genre_text)\n",
    "        \n",
    "        genre_embeddings = self.sentence_model.encode(\n",
    "            genre_texts, convert_to_tensor=True, device=device, batch_size=64\n",
    "        )\n",
    "        \n",
    "        # Concatenate title and genre embeddings\n",
    "        movie_embeddings = torch.cat([title_embeddings, genre_embeddings], dim=1)\n",
    "        \n",
    "        print(f\"Title embeddings shape: {title_embeddings.shape}\")\n",
    "        print(f\"Genre embeddings shape: {genre_embeddings.shape}\")\n",
    "        print(f\"Combined movie embeddings shape: {movie_embeddings.shape}\")\n",
    "        \n",
    "        # Normalize the embeddings for better training stability\n",
    "        print(\"Normalizing movie embeddings...\")\n",
    "        movie_embeddings_normalized = F.normalize(movie_embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Print normalization stats\n",
    "        print(f\"Original embeddings - mean: {movie_embeddings.mean().item():.4f}, std: {movie_embeddings.std().item():.4f}\")\n",
    "        print(f\"Normalized embeddings - mean: {movie_embeddings_normalized.mean().item():.4f}, std: {movie_embeddings_normalized.std().item():.4f}\")\n",
    "        \n",
    "        # Cache features for quick lookup (move to CPU for storage)\n",
    "        for idx, row in movies_df.iterrows():\n",
    "            movie_id = int(row['movie_id'])\n",
    "            # Store normalized embeddings on CPU to avoid memory issues\n",
    "            self.movie_features_cache[movie_id] = movie_embeddings_normalized[idx].cpu()\n",
    "            \n",
    "        self.movie_feature_dim = movie_embeddings_normalized.shape[1]\n",
    "        print(f\"Movie feature dimension: {self.movie_feature_dim}\")\n",
    "        return movie_embeddings_normalized\n",
    "    \n",
    "    def get_user_features(self, user_id):\n",
    "        \"\"\"Get cached user features\"\"\"\n",
    "        return self.user_features_cache.get(user_id, torch.zeros(self.user_feature_dim))\n",
    "    \n",
    "    def get_movie_features(self, movie_id):\n",
    "        \"\"\"Get cached movie features\"\"\"\n",
    "        return self.movie_features_cache.get(movie_id, torch.zeros(self.movie_feature_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30cc660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing user and movie features...\n",
      "Preparing user features...\n",
      "User features shape: (6040, 30)\n",
      "User feature columns: ['user_id', 'gender', 'age_1', 'age_18', 'age_25', 'age_35', 'age_45', 'age_50', 'age_56', 'occ_0', 'occ_1', 'occ_2', 'occ_3', 'occ_4', 'occ_5', 'occ_6', 'occ_7', 'occ_8', 'occ_9', 'occ_10', 'occ_11', 'occ_12', 'occ_13', 'occ_14', 'occ_15', 'occ_16', 'occ_17', 'occ_18', 'occ_19', 'occ_20']\n",
      "User feature dtypes:\n",
      "user_id    float64\n",
      "gender     float64\n",
      "age_1      float64\n",
      "age_18     float64\n",
      "age_25     float64\n",
      "age_35     float64\n",
      "age_45     float64\n",
      "age_50     float64\n",
      "age_56     float64\n",
      "occ_0      float64\n",
      "occ_1      float64\n",
      "occ_2      float64\n",
      "occ_3      float64\n",
      "occ_4      float64\n",
      "occ_5      float64\n",
      "occ_6      float64\n",
      "occ_7      float64\n",
      "occ_8      float64\n",
      "occ_9      float64\n",
      "occ_10     float64\n",
      "occ_11     float64\n",
      "occ_12     float64\n",
      "occ_13     float64\n",
      "occ_14     float64\n",
      "occ_15     float64\n",
      "occ_16     float64\n",
      "occ_17     float64\n",
      "occ_18     float64\n",
      "occ_19     float64\n",
      "occ_20     float64\n",
      "dtype: object\n",
      "User feature dimension: 29\n",
      "Using device: cpu\n",
      "Preparing movie features with sentence transformers...\n",
      "Loading sentence transformer model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding movie titles...\n",
      "Encoding movie genres...\n",
      "Title embeddings shape: torch.Size([3883, 384])\n",
      "Genre embeddings shape: torch.Size([3883, 384])\n",
      "Combined movie embeddings shape: torch.Size([3883, 768])\n",
      "Normalizing movie embeddings...\n",
      "Original embeddings - mean: 0.0010, std: 0.0510\n",
      "Normalized embeddings - mean: 0.0007, std: 0.0361\n",
      "Movie feature dimension: 768\n",
      "\n",
      "Feature preparation complete!\n",
      "User feature dimension: 29\n",
      "Movie feature dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Initialize feature processor and prepare features\n",
    "print(\"Preparing user and movie features...\")\n",
    "\n",
    "# Initialize feature processor\n",
    "feature_processor = FeatureProcessor()\n",
    "\n",
    "# Prepare user features\n",
    "user_features_df = feature_processor.prepare_user_features(users)\n",
    "\n",
    "# Prepare movie features  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "movie_embeddings = feature_processor.prepare_movie_features(movies, device=device)\n",
    "\n",
    "print(f\"\\nFeature preparation complete!\")\n",
    "print(f\"User feature dimension: {feature_processor.user_feature_dim}\")\n",
    "print(f\"Movie feature dimension: {feature_processor.movie_feature_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc83867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 97208 entries, 799 to 998118\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   user_id    97208 non-null  int64\n",
      " 1   movie_id   97208 non-null  int64\n",
      " 2   rating     97208 non-null  int64\n",
      " 3   timestamp  97208 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f538cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rank_latest'] = ratings.groupby(['user_id'])['timestamp'] \\\n",
    "                                .rank(method = 'first',ascending=False)\n",
    "\n",
    "train_ratings = ratings[ratings['rank_latest'].isin([1,2])]\n",
    "validation_ratings = ratings[ratings['rank_latest'] == 1]\n",
    "test_ratings = ratings[ratings['rank_latest'] == 2]\n",
    "\n",
    "# drop columns that we no Longer need \n",
    "train_ratings = train_ratings[['user_id', 'movie_id', 'rating']]\n",
    "test_ratings = test_ratings[['user_id','movie_id','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228a99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings['user_id'].max()+1\n",
    "num_items = ratings['movie_id'].max()+1\n",
    "\n",
    "all_movieIds = ratings['movie_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f50445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensTrainDataset(Dataset):\n",
    "    \"\"\"MovieLens Pytorch Dataset for Training\n",
    "    Args:\n",
    "        ratings(pd.DataFrame): Dataframe containing the movie ratings\n",
    "        all_movieIds (list): List containing all movieIds\n",
    "    \"\"\"\n",
    "    def __init__(self, ratings, all_movieIds):\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_movieIds)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "    \n",
    "    def get_dataset(self, ratings, all_movieIds):\n",
    "        users, items, labels = [], [], []\n",
    "        user_item_set = set(zip(ratings['user_id'], ratings['movie_id']))\n",
    "        \n",
    "        num_negatives = 4\n",
    "        for u, i in user_item_set:\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1)\n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_movieIds)\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0)\n",
    "        \n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tqmos8wakln",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedMovieLensTrainDataset(Dataset):\n",
    "    \"\"\"Optimized MovieLens Dataset using Candidate Generator for Negative Sampling with Features\n",
    "    Args:\n",
    "        ratings(pd.DataFrame): Dataframe containing the movie ratings\n",
    "        candidate_generator(CandidateGenerator): Optimized candidate generator\n",
    "        feature_processor(FeatureProcessor): Feature processor for user and movie features\n",
    "        num_negatives(int): Number of negative samples per positive sample\n",
    "        negative_method(str): Method for generating negative candidates\n",
    "        sampling_strategy(str): Strategy for negative sampling ('unique_per_user', 'per_positive', 'stratified')\n",
    "    \"\"\"\n",
    "    def __init__(self, ratings, candidate_generator, feature_processor, num_negatives=4, negative_method=\"hybrid\", sampling_strategy=\"unique_per_user\"):\n",
    "        self.ratings = ratings\n",
    "        self.candidate_generator = candidate_generator\n",
    "        self.feature_processor = feature_processor\n",
    "        self.num_negatives = num_negatives\n",
    "        self.negative_method = negative_method\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.user_features, self.movie_features, self.labels = self.get_dataset()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.user_features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_features[idx], self.movie_features[idx], self.labels[idx]\n",
    "    \n",
    "    def get_dataset(self):\n",
    "        user_features_list, movie_features_list, labels = [], [], []\n",
    "        \n",
    "        print(f\"Generating training dataset with {self.negative_method} negative sampling\")\n",
    "        print(f\"Sampling strategy: {self.sampling_strategy}\")\n",
    "        \n",
    "        # Process each user to generate negatives using candidate generator\n",
    "        user_positive_items = self.ratings.groupby('user_id')['movie_id'].apply(list).to_dict()\n",
    "        \n",
    "        for user_id, positive_items in tqdm(user_positive_items.items(), desc=\"Processing users\"):\n",
    "            # Get user features once for this user\n",
    "            user_feat = self.feature_processor.get_user_features(user_id)\n",
    "            \n",
    "            # Add positive samples\n",
    "            for item_id in positive_items:\n",
    "                movie_feat = self.feature_processor.get_movie_features(item_id)\n",
    "                user_features_list.append(user_feat)\n",
    "                movie_features_list.append(movie_feat)\n",
    "                labels.append(1)\n",
    "            \n",
    "            # Generate negatives based on sampling strategy\n",
    "            if self.sampling_strategy == \"unique_per_user\":\n",
    "                self._add_unique_negatives_per_user(user_features_list, movie_features_list, labels, user_id, user_feat, positive_items)\n",
    "            elif self.sampling_strategy == \"per_positive\":\n",
    "                self._add_negatives_per_positive(user_features_list, movie_features_list, labels, user_id, user_feat, positive_items)\n",
    "            elif self.sampling_strategy == \"stratified\":\n",
    "                self._add_stratified_negatives(user_features_list, movie_features_list, labels, user_id, user_feat, positive_items)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown sampling strategy: {self.sampling_strategy}\")\n",
    "        \n",
    "        print(f\"Generated {len(user_features_list)} samples ({labels.count(1)} positive, {labels.count(0)} negative)\")\n",
    "        print(f\"Negative-to-positive ratio: {labels.count(0) / labels.count(1):.2f}\")\n",
    "        \n",
    "        # Convert to tensors\n",
    "        user_features_tensor = torch.stack(user_features_list)\n",
    "        movie_features_tensor = torch.stack(movie_features_list)\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        return user_features_tensor, movie_features_tensor, labels_tensor\n",
    "    \n",
    "    def _add_unique_negatives_per_user(self, user_features_list, movie_features_list, labels, user_id, user_feat, positive_items):\n",
    "        \"\"\"Add unique negative samples per user (most efficient approach)\"\"\"\n",
    "        total_negatives_needed = len(positive_items) * self.num_negatives\n",
    "        \n",
    "        # Generate candidate pool\n",
    "        negative_candidates = self.candidate_generator.generate_candidates(\n",
    "            user_id, \n",
    "            method=self.negative_method, \n",
    "            num_candidates=min(total_negatives_needed * 2, 300)  # Get more candidates than needed\n",
    "        )\n",
    "        \n",
    "        # Filter out positive items to ensure no overlap\n",
    "        negative_candidates = [item for item in negative_candidates if item not in positive_items]\n",
    "        \n",
    "        # Sample unique negatives\n",
    "        if len(negative_candidates) > 0:\n",
    "            sample_size = min(total_negatives_needed, len(negative_candidates))\n",
    "            sampled_negatives = np.random.choice(\n",
    "                negative_candidates,\n",
    "                size=sample_size,\n",
    "                replace=False\n",
    "            )\n",
    "            \n",
    "            # Add all sampled negatives for this user\n",
    "            for neg_item in sampled_negatives:\n",
    "                movie_feat = self.feature_processor.get_movie_features(neg_item)\n",
    "                user_features_list.append(user_feat)\n",
    "                movie_features_list.append(movie_feat)\n",
    "                labels.append(0)\n",
    "    \n",
    "    def _add_negatives_per_positive(self, user_features_list, movie_features_list, labels, user_id, user_feat, positive_items):\n",
    "        \"\"\"Add negatives per positive item (original intended approach but fixed)\"\"\"\n",
    "        # Generate candidate pool once per user\n",
    "        negative_candidates = self.candidate_generator.generate_candidates(\n",
    "            user_id,\n",
    "            method=self.negative_method,\n",
    "            num_candidates=min(len(positive_items) * self.num_negatives * 2, 300)\n",
    "        )\n",
    "        \n",
    "        # Filter out positive items\n",
    "        negative_candidates = [item for item in negative_candidates if item not in positive_items]\n",
    "        \n",
    "        if len(negative_candidates) == 0:\n",
    "            return\n",
    "        \n",
    "        # For each positive item, sample unique negatives\n",
    "        all_used_negatives = set()\n",
    "        for _ in positive_items:\n",
    "            # Available negatives (excluding already used ones)\n",
    "            available_negatives = [item for item in negative_candidates if item not in all_used_negatives]\n",
    "            \n",
    "            if len(available_negatives) == 0:\n",
    "                break\n",
    "                \n",
    "            # Sample negatives for this positive item\n",
    "            sample_size = min(self.num_negatives, len(available_negatives))\n",
    "            sampled_negatives = np.random.choice(\n",
    "                available_negatives,\n",
    "                size=sample_size,\n",
    "                replace=False\n",
    "            )\n",
    "            \n",
    "            # Add negatives and mark as used\n",
    "            for neg_item in sampled_negatives:\n",
    "                movie_feat = self.feature_processor.get_movie_features(neg_item)\n",
    "                user_features_list.append(user_feat)\n",
    "                movie_features_list.append(movie_feat)\n",
    "                labels.append(0)\n",
    "                all_used_negatives.add(neg_item)\n",
    "    \n",
    "    def _add_stratified_negatives(self, user_features_list, movie_features_list, labels, user_id, user_feat, positive_items):\n",
    "        \"\"\"Add stratified negatives from different candidate methods\"\"\"\n",
    "        total_negatives_needed = len(positive_items) * self.num_negatives\n",
    "        \n",
    "        # Get negatives from different strategies\n",
    "        methods = [\"popularity\", \"collaborative\", \"content\"]\n",
    "        negatives_per_method = total_negatives_needed // len(methods)\n",
    "        \n",
    "        all_negatives = []\n",
    "        \n",
    "        for method in methods:\n",
    "            method_candidates = self.candidate_generator.generate_candidates(\n",
    "                user_id,\n",
    "                method=method,\n",
    "                num_candidates=negatives_per_method * 2\n",
    "            )\n",
    "            # Filter out positives and already selected negatives\n",
    "            method_candidates = [item for item in method_candidates \n",
    "                               if item not in positive_items and item not in all_negatives]\n",
    "            \n",
    "            # Sample from this method\n",
    "            if len(method_candidates) > 0:\n",
    "                sample_size = min(negatives_per_method, len(method_candidates))\n",
    "                sampled = np.random.choice(method_candidates, size=sample_size, replace=False)\n",
    "                all_negatives.extend(sampled)\n",
    "        \n",
    "        # Fill remaining slots with random negatives if needed\n",
    "        remaining_slots = total_negatives_needed - len(all_negatives)\n",
    "        if remaining_slots > 0:\n",
    "            available_items = self.candidate_generator.get_available_items(user_id)\n",
    "            remaining_items = [item for item in available_items if item not in all_negatives]\n",
    "            \n",
    "            if len(remaining_items) > 0:\n",
    "                sample_size = min(remaining_slots, len(remaining_items))\n",
    "                additional_negatives = np.random.choice(remaining_items, size=sample_size, replace=False)\n",
    "                all_negatives.extend(additional_negatives)\n",
    "        \n",
    "        # Add all negatives for this user\n",
    "        for neg_item in all_negatives:\n",
    "            movie_feat = self.feature_processor.get_movie_features(neg_item)\n",
    "            user_features_list.append(user_feat)\n",
    "            movie_features_list.append(movie_feat)\n",
    "            labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df34dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing optimized candidate generator...\n",
      "Candidate generator initialized!\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Global data structures for fast candidate generation\n",
    "class CandidateGenerator:\n",
    "    def __init__(self, train_ratings, movies, all_movieIds):\n",
    "        self.train_ratings = train_ratings\n",
    "        self.movies = movies\n",
    "        self.all_movieIds = all_movieIds\n",
    "        self.user_interacted_items = train_ratings.groupby('user_id')['movie_id'].apply(list).to_dict()\n",
    "        \n",
    "        # Pre-compute global data structures\n",
    "        self._precompute_popularity()\n",
    "        self._precompute_movie_genres()\n",
    "        self._precompute_user_similarity()\n",
    "        self._precompute_genre_profiles()\n",
    "        \n",
    "    def _precompute_popularity(self):\n",
    "        \"\"\"Pre-compute item popularity ranking\"\"\"\n",
    "        self.item_popularity = self.train_ratings['movie_id'].value_counts()\n",
    "        self.popular_items = self.item_popularity.index.tolist()\n",
    "        \n",
    "    def _precompute_movie_genres(self):\n",
    "        \"\"\"Create movie-to-genres dictionary for O(1) lookups\"\"\"\n",
    "        self.movie_to_genres = {}\n",
    "        for _, row in self.movies.iterrows():\n",
    "            self.movie_to_genres[row['movie_id']] = row['genres'].split('|')\n",
    "            \n",
    "    def _precompute_user_similarity(self):\n",
    "        \"\"\"Pre-compute user similarity matrix using vectorized operations\"\"\"\n",
    "        # Create user-item matrix\n",
    "        users = list(self.user_interacted_items.keys())\n",
    "        user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "        \n",
    "        # Build sparse matrix\n",
    "        rows, cols = [], []\n",
    "        for user_id, items in self.user_interacted_items.items():\n",
    "            user_idx = user_to_idx[user_id]\n",
    "            for item in items:\n",
    "                rows.append(user_idx)\n",
    "                cols.append(item)\n",
    "        \n",
    "        # Create binary user-item matrix\n",
    "        data = np.ones(len(rows))\n",
    "        self.user_item_matrix = csr_matrix((data, (rows, cols)), \n",
    "                                          shape=(len(users), max(self.all_movieIds) + 1))\n",
    "        \n",
    "        # Compute user similarity (cosine similarity for efficiency)\n",
    "        self.user_similarity = cosine_similarity(self.user_item_matrix)\n",
    "        self.user_to_idx = user_to_idx\n",
    "        self.idx_to_user = {idx: user for user, idx in user_to_idx.items()}\n",
    "        \n",
    "    def _precompute_genre_profiles(self):\n",
    "        \"\"\"Pre-compute genre profiles for users\"\"\"\n",
    "        self.user_genre_profiles = {}\n",
    "        all_genres = set()\n",
    "        \n",
    "        # Extract all unique genres\n",
    "        for genres_list in self.movie_to_genres.values():\n",
    "            all_genres.update(genres_list)\n",
    "        \n",
    "        self.all_genres = list(all_genres)\n",
    "        self.genre_to_idx = {genre: idx for idx, genre in enumerate(self.all_genres)}\n",
    "        \n",
    "        # Build user genre profiles\n",
    "        for user_id, items in self.user_interacted_items.items():\n",
    "            genre_counts = defaultdict(int)\n",
    "            for item in items:\n",
    "                if item in self.movie_to_genres:\n",
    "                    for genre in self.movie_to_genres[item]:\n",
    "                        genre_counts[genre] += 1\n",
    "            self.user_genre_profiles[user_id] = dict(genre_counts)\n",
    "            \n",
    "    @lru_cache(maxsize=1000)\n",
    "    def get_available_items(self, user_id):\n",
    "        \"\"\"Cache available items for users\"\"\"\n",
    "        interacted_items = set(self.user_interacted_items.get(user_id, []))\n",
    "        all_items_set = set(self.all_movieIds)\n",
    "        return list(all_items_set - interacted_items)\n",
    "    \n",
    "    def generate_popularity_candidates(self, user_id, num_candidates=100):\n",
    "        \"\"\"Optimized popularity-based candidate generation\"\"\"\n",
    "        available_items = set(self.get_available_items(user_id))\n",
    "        \n",
    "        candidates = []\n",
    "        for item in self.popular_items:\n",
    "            if item in available_items:\n",
    "                candidates.append(item)\n",
    "                if len(candidates) >= num_candidates:\n",
    "                    break\n",
    "        \n",
    "        return candidates[:num_candidates]\n",
    "    \n",
    "    def generate_collaborative_candidates(self, user_id, num_candidates=100):\n",
    "        \"\"\"Optimized collaborative filtering using pre-computed similarity\"\"\"\n",
    "        if user_id not in self.user_to_idx:\n",
    "            return self.get_available_items(user_id)[:num_candidates]\n",
    "        \n",
    "        user_idx = self.user_to_idx[user_id]\n",
    "        available_items = set(self.get_available_items(user_id))\n",
    "        \n",
    "        # Get most similar users\n",
    "        similarities = self.user_similarity[user_idx]\n",
    "        similar_user_indices = np.argsort(similarities)[-51:-1]  # Top 50 similar users\n",
    "        \n",
    "        # Score candidates based on similar users\n",
    "        candidate_scores = defaultdict(float)\n",
    "        for similar_idx in similar_user_indices:\n",
    "            similar_user_id = self.idx_to_user[similar_idx]\n",
    "            similarity_score = similarities[similar_idx]\n",
    "            \n",
    "            if similarity_score > 0.1:  # Threshold\n",
    "                for item in self.user_interacted_items.get(similar_user_id, []):\n",
    "                    if item in available_items:\n",
    "                        candidate_scores[item] += similarity_score\n",
    "        \n",
    "        # Sort by score and return top candidates\n",
    "        sorted_candidates = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [item for item, score in sorted_candidates[:num_candidates]]\n",
    "    \n",
    "    def generate_content_candidates(self, user_id, num_candidates=100):\n",
    "        \"\"\"Optimized content-based filtering using pre-computed genre profiles\"\"\"\n",
    "        user_genres = self.user_genre_profiles.get(user_id, {})\n",
    "        if not user_genres:\n",
    "            return self.get_available_items(user_id)[:num_candidates]\n",
    "        \n",
    "        available_items = set(self.get_available_items(user_id))\n",
    "        \n",
    "        # Score items by genre overlap\n",
    "        candidate_scores = {}\n",
    "        for item in available_items:\n",
    "            if item in self.movie_to_genres:\n",
    "                score = 0\n",
    "                for genre in self.movie_to_genres[item]:\n",
    "                    score += user_genres.get(genre, 0)\n",
    "                if score > 0:\n",
    "                    candidate_scores[item] = score\n",
    "        \n",
    "        # Sort by score and return top candidates\n",
    "        sorted_candidates = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [item for item, score in sorted_candidates[:num_candidates]]\n",
    "    \n",
    "    def generate_hybrid_candidates(self, user_id, num_candidates=100):\n",
    "        \"\"\"Optimized hybrid candidate generation\"\"\"\n",
    "        # Get candidates from each method\n",
    "        pop_candidates = self.generate_popularity_candidates(user_id, num_candidates//3)\n",
    "        collab_candidates = self.generate_collaborative_candidates(user_id, num_candidates//3)\n",
    "        content_candidates = self.generate_content_candidates(user_id, num_candidates//3)\n",
    "        \n",
    "        # Combine and deduplicate using set operations\n",
    "        hybrid_candidates = list(dict.fromkeys(pop_candidates + collab_candidates + content_candidates))\n",
    "        \n",
    "        # Fill remaining slots with random items\n",
    "        remaining_slots = num_candidates - len(hybrid_candidates)\n",
    "        if remaining_slots > 0:\n",
    "            available_items = set(self.get_available_items(user_id))\n",
    "            remaining_items = list(available_items - set(hybrid_candidates))\n",
    "            if remaining_items:\n",
    "                random_indices = np.random.choice(len(remaining_items), \n",
    "                                                size=min(remaining_slots, len(remaining_items)), \n",
    "                                                replace=False)\n",
    "                hybrid_candidates.extend([remaining_items[i] for i in random_indices])\n",
    "        \n",
    "        return hybrid_candidates[:num_candidates]\n",
    "    \n",
    "    def generate_candidates(self, user_id, method=\"hybrid\", num_candidates=100):\n",
    "        \"\"\"Main interface for candidate generation\"\"\"\n",
    "        if method == \"popularity\":\n",
    "            return self.generate_popularity_candidates(user_id, num_candidates)\n",
    "        elif method == \"collaborative\":\n",
    "            return self.generate_collaborative_candidates(user_id, num_candidates)\n",
    "        elif method == \"content\":\n",
    "            return self.generate_content_candidates(user_id, num_candidates)\n",
    "        elif method == \"hybrid\":\n",
    "            return self.generate_hybrid_candidates(user_id, num_candidates)\n",
    "        else:\n",
    "            # Random fallback\n",
    "            available_items = self.get_available_items(user_id)\n",
    "            indices = np.random.choice(len(available_items), \n",
    "                                     size=min(num_candidates, len(available_items)), \n",
    "                                     replace=False)\n",
    "            return [available_items[i] for i in indices]\n",
    "\n",
    "# Initialize the optimized candidate generator\n",
    "print(\"Initializing optimized candidate generator...\")\n",
    "candidate_gen = CandidateGenerator(ratings, movies, all_movieIds)\n",
    "print(\"Candidate generator initialized!\")\n",
    "\n",
    "# Backward compatibility function\n",
    "def generate_candidates(user_id, method=\"hybrid\", num_candidates=100):\n",
    "    \"\"\"Backward compatible interface\"\"\"\n",
    "    return candidate_gen.generate_candidates(user_id, method, num_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7716b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    \"\"\" Neural Collaborative Filtering (NCF) with Features\n",
    "    \n",
    "        Args:\n",
    "            user_feature_dim (int): Dimension of user features\n",
    "            movie_feature_dim (int): Dimension of movie features\n",
    "            ratings (pd.DataFrame): Dataframe containing the movie ratings for training\n",
    "            feature_processor (FeatureProcessor): Feature processor for user and movie features\n",
    "            candidate_generator (CandidateGenerator): Candidate generator for negative sampling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, user_feature_dim, movie_feature_dim, ratings, feature_processor, candidate_generator):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store parameters\n",
    "        self.user_feature_dim = user_feature_dim\n",
    "        self.movie_feature_dim = movie_feature_dim\n",
    "        self.ratings = ratings\n",
    "        self.feature_processor = feature_processor\n",
    "        self.candidate_generator = candidate_generator\n",
    "        \n",
    "        # Feature processing layers\n",
    "        self.user_fc = nn.Linear(user_feature_dim, 64)\n",
    "        self.movie_fc = nn.Linear(movie_feature_dim, 64)\n",
    "        \n",
    "        # NCF layers\n",
    "        self.fc1 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, user_features, movie_features):\n",
    "        \"\"\"\n",
    "        Forward pass with user and movie feature vectors\n",
    "        \n",
    "        Args:\n",
    "            user_features: Tensor of user features [batch_size, user_feature_dim]\n",
    "            movie_features: Tensor of movie features [batch_size, movie_feature_dim]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Process features through initial layers\n",
    "        user_processed = nn.ReLU()(self.user_fc(user_features))\n",
    "        movie_processed = nn.ReLU()(self.movie_fc(movie_features))\n",
    "        \n",
    "        # Concat the processed features\n",
    "        vector = torch.cat([user_processed, movie_processed], dim=-1)\n",
    "        \n",
    "        # Pass through dense layers\n",
    "        vector = self.dropout(nn.ReLU()(self.fc1(vector)))\n",
    "        vector = self.dropout(nn.ReLU()(self.fc2(vector)))\n",
    "\n",
    "        # Output layer\n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def compute_loss(self, batch):\n",
    "        user_features, movie_features, labels = batch\n",
    "        predicted_labels = self(user_features, movie_features)\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "\n",
    "    def get_dataloader(self, batch_size=512, num_workers=4, num_negatives=4):\n",
    "        dataset = OptimizedMovieLensTrainDataset(\n",
    "            self.ratings, \n",
    "            self.candidate_generator,\n",
    "            self.feature_processor,\n",
    "            num_negatives=num_negatives,\n",
    "            negative_method=\"hybrid\",\n",
    "            sampling_strategy=\"unique_per_user\"\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "o1hljtu6ti",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedNCF(nn.Module):\n",
    "    \"\"\" Optimized Neural Collaborative Filtering (NCF) with Features and Smart Negative Sampling\n",
    "    \n",
    "        Args:\n",
    "            user_feature_dim (int): Dimension of user features\n",
    "            movie_feature_dim (int): Dimension of movie features\n",
    "            ratings (pd.DataFrame): Dataframe containing the movie ratings for training\n",
    "            feature_processor (FeatureProcessor): Feature processor for user and movie features\n",
    "            candidate_generator (CandidateGenerator): Optimized candidate generator\n",
    "            negative_method (str): Method for negative sampling\n",
    "            sampling_strategy (str): Strategy for negative sampling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, user_feature_dim, movie_feature_dim, ratings, feature_processor, candidate_generator, \n",
    "                 negative_method=\"hybrid\", sampling_strategy=\"unique_per_user\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store parameters\n",
    "        self.user_feature_dim = user_feature_dim\n",
    "        self.movie_feature_dim = movie_feature_dim\n",
    "        self.ratings = ratings\n",
    "        self.feature_processor = feature_processor\n",
    "        self.candidate_generator = candidate_generator\n",
    "        self.negative_method = negative_method\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        \n",
    "        # Feature processing layers with batch normalization\n",
    "        self.user_fc1 = nn.Linear(user_feature_dim, 128)\n",
    "        self.user_bn1 = nn.BatchNorm1d(128)\n",
    "        self.user_fc2 = nn.Linear(128, 64)\n",
    "        self.user_bn2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.movie_fc1 = nn.Linear(movie_feature_dim, 256)\n",
    "        self.movie_bn1 = nn.BatchNorm1d(256)\n",
    "        self.movie_fc2 = nn.Linear(256, 128)\n",
    "        self.movie_bn2 = nn.BatchNorm1d(128)\n",
    "        self.movie_fc3 = nn.Linear(128, 64)\n",
    "        self.movie_bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        # NCF layers\n",
    "        self.fc1 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, user_features, movie_features):\n",
    "        \"\"\"\n",
    "        Forward pass with user and movie feature vectors\n",
    "        \n",
    "        Args:\n",
    "            user_features: Tensor of user features [batch_size, user_feature_dim]\n",
    "            movie_features: Tensor of movie features [batch_size, movie_feature_dim]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Process user features\n",
    "        user_x = self.dropout(nn.ReLU()(self.user_bn1(self.user_fc1(user_features))))\n",
    "        user_processed = nn.ReLU()(self.user_bn2(self.user_fc2(user_x)))\n",
    "        \n",
    "        # Process movie features\n",
    "        movie_x = self.dropout(nn.ReLU()(self.movie_bn1(self.movie_fc1(movie_features))))\n",
    "        movie_x = self.dropout(nn.ReLU()(self.movie_bn2(self.movie_fc2(movie_x))))\n",
    "        movie_processed = nn.ReLU()(self.movie_bn3(self.movie_fc3(movie_x)))\n",
    "        \n",
    "        # Concat the processed features\n",
    "        vector = torch.cat([user_processed, movie_processed], dim=-1)\n",
    "        \n",
    "        # Pass through NCF layers\n",
    "        vector = self.dropout(nn.ReLU()(self.fc1(vector)))\n",
    "        vector = self.dropout(nn.ReLU()(self.fc2(vector)))\n",
    "\n",
    "        # Output layer\n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def compute_loss(self, batch):\n",
    "        user_features, movie_features, labels = batch\n",
    "        predicted_labels = self(user_features, movie_features)\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "\n",
    "    def get_dataloader(self, batch_size=512, num_workers=4, num_negatives=4):\n",
    "        \"\"\"Get DataLoader with optimized negative sampling\"\"\"\n",
    "        dataset = OptimizedMovieLensTrainDataset(\n",
    "            self.ratings, \n",
    "            self.candidate_generator,\n",
    "            self.feature_processor,\n",
    "            num_negatives=num_negatives,\n",
    "            negative_method=self.negative_method,\n",
    "            sampling_strategy=self.sampling_strategy\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a555y7g5r7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing candidates for 604 validation users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d1f973b1ef4a7c9d750f667d2255e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing candidates:   0%|          | 0/604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed candidates for 604 users\n"
     ]
    }
   ],
   "source": [
    "# Precompute validation candidates for faster validation\n",
    "def precompute_validation_candidates(validation_ratings, candidate_method=\"hybrid\", num_candidates=100):\n",
    "    \"\"\"\n",
    "    Precompute candidates for all validation users to speed up validation\n",
    "    \n",
    "    Returns:\n",
    "        dict: {user_id: [candidate_items]}\n",
    "    \"\"\"\n",
    "    validation_users = validation_ratings['user_id'].unique()\n",
    "    precomputed_candidates = {}\n",
    "    \n",
    "    print(f\"Precomputing candidates for {len(validation_users)} validation users...\")\n",
    "    \n",
    "    for user_id in tqdm(validation_users, desc=\"Precomputing candidates\"):\n",
    "        candidates = generate_candidates(user_id, method=candidate_method, num_candidates=num_candidates)\n",
    "        precomputed_candidates[user_id] = candidates\n",
    "    \n",
    "    print(f\"Precomputed candidates for {len(precomputed_candidates)} users\")\n",
    "    return precomputed_candidates\n",
    "\n",
    "# Precompute candidates before training\n",
    "validation_candidates = precompute_validation_candidates(validation_ratings, candidate_method=\"hybrid\", num_candidates=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c04a928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated validation function for features-based models\n",
    "def validate_model_with_features(model, test_ratings, precomputed_candidates, device, total_users_to_test=20, k=10):\n",
    "    \"\"\"\n",
    "    Validation function that works with features instead of IDs\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model (with feature processor)\n",
    "        test_ratings: DataFrame with validation ratings\n",
    "        precomputed_candidates: Dict of {user_id: [candidate_items]}\n",
    "        device: torch device\n",
    "        total_users_to_test: Number of users to test\n",
    "        k: Top-k for hit ratio calculation\n",
    "    \"\"\"\n",
    "    test_user_item_set = list(set(zip(test_ratings['user_id'], test_ratings['movie_id'])))\n",
    "    hits = []\n",
    "    ranks = []\n",
    "    skipped_cases = 0\n",
    "    total_cases = 0\n",
    "\n",
    "    for (u, i) in tqdm(test_user_item_set[:total_users_to_test]):\n",
    "        total_cases += 1\n",
    "        \n",
    "        # Check if user and movie are in our feature caches\n",
    "        if u not in model.feature_processor.user_features_cache:\n",
    "            print(f\"Skipping user {u} - not in feature cache\")\n",
    "            skipped_cases += 1\n",
    "            continue\n",
    "            \n",
    "        if i not in model.feature_processor.movie_features_cache:\n",
    "            print(f\"Skipping movie {i} - not in feature cache\")\n",
    "            skipped_cases += 1\n",
    "            continue\n",
    "        \n",
    "        # Use precomputed candidates\n",
    "        candidate_items = precomputed_candidates.get(u, [])\n",
    "        \n",
    "        # Make sure the test item is included\n",
    "        if i not in candidate_items:\n",
    "            candidate_items = candidate_items + [i]\n",
    "        \n",
    "        # Filter candidates to only include movies with features\n",
    "        valid_candidates = [\n",
    "            movie_id for movie_id in candidate_items \n",
    "            if movie_id in model.feature_processor.movie_features_cache\n",
    "        ]\n",
    "        \n",
    "        if len(valid_candidates) == 0:\n",
    "            print(f\"No valid candidates for user {u}\")\n",
    "            skipped_cases += 1\n",
    "            continue\n",
    "            \n",
    "        if i not in valid_candidates:\n",
    "            print(f\"Target movie {i} not in valid candidates for user {u}\")\n",
    "            skipped_cases += 1\n",
    "            continue\n",
    "        \n",
    "        # Get user features\n",
    "        user_feat = model.feature_processor.get_user_features(u).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Score candidates using features\n",
    "        predicted_scores = []\n",
    "        for movie_id in valid_candidates:\n",
    "            movie_feat = model.feature_processor.get_movie_features(movie_id).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                score = model(user_feat, movie_feat).item()\n",
    "            predicted_scores.append(score)\n",
    "        \n",
    "        # Find rank and hit\n",
    "        sorted_indices = sorted(range(len(predicted_scores)), key=lambda idx: predicted_scores[idx], reverse=True)\n",
    "        sorted_items = [valid_candidates[idx] for idx in sorted_indices]\n",
    "        relevant_item_rank = sorted_items.index(i) + 1\n",
    "        ranks.append(relevant_item_rank)\n",
    "        \n",
    "        if relevant_item_rank <= k:\n",
    "            hits.append(1)\n",
    "        else:\n",
    "            hits.append(0)\n",
    "            \n",
    "        # Debug: Print first few cases\n",
    "        if len(hits) <= 3:\n",
    "            target_score = predicted_scores[valid_candidates.index(i)] if i in valid_candidates else \"N/A\"\n",
    "            print(f\"User {u}, Movie {i}: Score={target_score}, Rank={relevant_item_rank}/{len(valid_candidates)}\")\n",
    "\n",
    "    print(f\"\\nValidation Summary:\")\n",
    "    print(f\"Total test cases: {total_cases}\")\n",
    "    print(f\"Skipped cases: {skipped_cases}\")\n",
    "    print(f\"Valid cases processed: {len(hits)}\")\n",
    "    \n",
    "    if len(hits) == 0:\n",
    "        print(\"Warning: No valid test cases found!\")\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    # Calculate metrics\n",
    "    hits_tensor = torch.tensor(hits, dtype=torch.float32)\n",
    "    ranks_tensor = torch.tensor(ranks, dtype=torch.float32)\n",
    "    \n",
    "    hit_ratio = hits_tensor.mean().item()\n",
    "    mrr = torch.mean(1.0 / ranks_tensor).item()\n",
    "    mean_rank = ranks_tensor.mean().item()\n",
    "    \n",
    "    print(f\"Hit Ratio @ {k}: {hit_ratio:.3f}\")\n",
    "    print(f\"Mean Rank: {mean_rank:.1f}\")\n",
    "    print(f\"MRR: {mrr:.3f}\")\n",
    "    \n",
    "    return hit_ratio, mrr, mean_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd673a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Training with UNIQUE_PER_USER sampling + HYBRID negatives\n",
      "======================================================================\n",
      "Generating training dataset with hybrid negative sampling\n",
      "Sampling strategy: unique_per_user\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec63decad0544ffbc42ba8faefad327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing users:   0%|          | 0/604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6040 samples (1208 positive, 4832 negative)\n",
      "Negative-to-positive ratio: 4.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdda5384c644a7a9b7cb564987eb06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a98c41a935432991dd7623abd87aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.3749134838581085, Rank=19/101\n",
      "User 3912, Movie 318: Score=0.3827151656150818, Rank=26/101\n",
      "User 1878, Movie 1920: Score=0.38291895389556885, Rank=33/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.150\n",
      "Mean Rank: 39.5\n",
      "MRR: 0.053\n",
      "Epoch 1/30\n",
      "  Training Loss: 0.5509\n",
      "  Hit Ratio @ 10: 0.150\n",
      "  Mean Rank: 39.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4b237af4b94efba9a907f85d7873c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f4bf2695864907965cc4c4f38a0450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.31022658944129944, Rank=13/101\n",
      "User 3912, Movie 318: Score=0.30032438039779663, Rank=55/101\n",
      "User 1878, Movie 1920: Score=0.3212267756462097, Rank=38/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.150\n",
      "Mean Rank: 30.0\n",
      "MRR: 0.101\n",
      "Epoch 2/30\n",
      "  Training Loss: 0.4361\n",
      "  Hit Ratio @ 10: 0.150\n",
      "  Mean Rank: 30.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2abc13b9164c2880a58294beeb8b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8446358e56c24c10aba7b2fa31366832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.4091329872608185, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.32761064171791077, Rank=71/101\n",
      "User 1878, Movie 1920: Score=0.40299496054649353, Rank=27/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.200\n",
      "Mean Rank: 28.1\n",
      "MRR: 0.107\n",
      "Epoch 3/30\n",
      "  Training Loss: 0.3899\n",
      "  Hit Ratio @ 10: 0.200\n",
      "  Mean Rank: 28.1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339d2f330a314da2b79d284e07c18690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932223197ec742f9ae6d5aec17c5a5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.4547901451587677, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.30193737149238586, Rank=72/101\n",
      "User 1878, Movie 1920: Score=0.43352991342544556, Rank=28/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.300\n",
      "Mean Rank: 23.4\n",
      "MRR: 0.096\n",
      "Epoch 4/30\n",
      "  Training Loss: 0.3703\n",
      "  Hit Ratio @ 10: 0.300\n",
      "  Mean Rank: 23.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dd8cbfa9f344df9b2a7f35d832abff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 5/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2398ce5073b4d25aaffabd04d9d89b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.47724881768226624, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.23362430930137634, Rank=70/101\n",
      "User 1878, Movie 1920: Score=0.4771513044834137, Rank=7/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 21.5\n",
      "MRR: 0.139\n",
      "Epoch 5/30\n",
      "  Training Loss: 0.3544\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 21.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985a5a6282614755a8c36465814fed62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 6/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb7c7f340504a19a3bd148e343280ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5017149448394775, Rank=13/101\n",
      "User 3912, Movie 318: Score=0.11771272122859955, Rank=72/101\n",
      "User 1878, Movie 1920: Score=0.5119661092758179, Rank=12/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.350\n",
      "Mean Rank: 21.3\n",
      "MRR: 0.116\n",
      "Epoch 6/30\n",
      "  Training Loss: 0.3454\n",
      "  Hit Ratio @ 10: 0.350\n",
      "  Mean Rank: 21.3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987c8dfbb144436c8c845286a447d775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 7/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd16acb343654f54bd8d1bc793b49bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.573489248752594, Rank=7/101\n",
      "User 3912, Movie 318: Score=0.19524624943733215, Rank=55/101\n",
      "User 1878, Movie 1920: Score=0.5662173628807068, Rank=8/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.400\n",
      "Mean Rank: 20.5\n",
      "MRR: 0.181\n",
      "Epoch 7/30\n",
      "  Training Loss: 0.3413\n",
      "  Hit Ratio @ 10: 0.400\n",
      "  Mean Rank: 20.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770684df21db4e92bf3d6fbc3cb50350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 8/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cb987450544acca4a583ef8e773442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5708229541778564, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.06519521027803421, Rank=65/101\n",
      "User 1878, Movie 1920: Score=0.6183537840843201, Rank=2/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.350\n",
      "Mean Rank: 17.4\n",
      "MRR: 0.203\n",
      "Epoch 8/30\n",
      "  Training Loss: 0.3299\n",
      "  Hit Ratio @ 10: 0.350\n",
      "  Mean Rank: 17.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0451aaec49d487d85c8509e5bf4d6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 9/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6205d8b24c634301ae8652212fe24716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6082326173782349, Rank=14/101\n",
      "User 3912, Movie 318: Score=0.07057066261768341, Rank=67/101\n",
      "User 1878, Movie 1920: Score=0.6689422726631165, Rank=2/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.350\n",
      "Mean Rank: 19.1\n",
      "MRR: 0.180\n",
      "Epoch 9/30\n",
      "  Training Loss: 0.3269\n",
      "  Hit Ratio @ 10: 0.350\n",
      "  Mean Rank: 19.1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4366f607f26c46a2a3efc4e4f22bba31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 10/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf8140bf22c43f588dc6417073216e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.634990394115448, Rank=10/101\n",
      "User 3912, Movie 318: Score=0.09014565497636795, Rank=59/101\n",
      "User 1878, Movie 1920: Score=0.6708040237426758, Rank=6/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 17.4\n",
      "MRR: 0.175\n",
      "Epoch 10/30\n",
      "  Training Loss: 0.3162\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 17.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b59161947b48fe95af6e55b8ec17e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 11/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d0d3fa9f064a88ab9d319bff1476a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.626845121383667, Rank=17/101\n",
      "User 3912, Movie 318: Score=0.09019966423511505, Rank=60/101\n",
      "User 1878, Movie 1920: Score=0.7156438231468201, Rank=5/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 17.3\n",
      "MRR: 0.173\n",
      "Epoch 11/30\n",
      "  Training Loss: 0.3016\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 17.3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872f3fe0daa6465a9e5390802be43fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 12/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec88c29d76df4767a556b754a8651e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.41987335681915283, Rank=23/101\n",
      "User 3912, Movie 318: Score=0.06340239197015762, Rank=65/101\n",
      "User 1878, Movie 1920: Score=0.6922929883003235, Rank=8/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.650\n",
      "Mean Rank: 15.9\n",
      "MRR: 0.218\n",
      "Epoch 12/30\n",
      "  Training Loss: 0.2992\n",
      "  Hit Ratio @ 10: 0.650\n",
      "  Mean Rank: 15.9\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae60522fb8f94c77950bde48b6d85c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 13/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4bf90d8a454bd0b0b43f1cda6da478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.5880275964736938, Rank=18/101\n",
      "User 3912, Movie 318: Score=0.05856947600841522, Rank=64/101\n",
      "User 1878, Movie 1920: Score=0.7012561559677124, Rank=5/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 15.4\n",
      "MRR: 0.201\n",
      "Epoch 13/30\n",
      "  Training Loss: 0.2933\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 15.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45abca93041f4906890d0e0989662700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 14/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66966dac9f6d424782d5cc07d8bf9dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6087841391563416, Rank=17/101\n",
      "User 3912, Movie 318: Score=0.06736541539430618, Rank=63/101\n",
      "User 1878, Movie 1920: Score=0.8232242465019226, Rank=2/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.550\n",
      "Mean Rank: 16.0\n",
      "MRR: 0.183\n",
      "Epoch 14/30\n",
      "  Training Loss: 0.2828\n",
      "  Hit Ratio @ 10: 0.550\n",
      "  Mean Rank: 16.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd69cf0fbd104256bdf57ba42ade576a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 15/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6511b4b2417f43f58dfa517bd60b132c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6367135643959045, Rank=15/101\n",
      "User 3912, Movie 318: Score=0.05487886816263199, Rank=65/101\n",
      "User 1878, Movie 1920: Score=0.8138770461082458, Rank=2/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.550\n",
      "Mean Rank: 15.2\n",
      "MRR: 0.153\n",
      "Epoch 15/30\n",
      "  Training Loss: 0.2772\n",
      "  Hit Ratio @ 10: 0.550\n",
      "  Mean Rank: 15.2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c24d011d15242afad0516096ddb9356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 16/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94a0b34df0349d29817a021c46c0f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6722294092178345, Rank=17/101\n",
      "User 3912, Movie 318: Score=0.05882631614804268, Rank=61/101\n",
      "User 1878, Movie 1920: Score=0.8332768678665161, Rank=2/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 17.4\n",
      "MRR: 0.139\n",
      "Epoch 16/30\n",
      "  Training Loss: 0.2674\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 17.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a84a8f42af48f88c8c53a2595af7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 17/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e5b7549ec546c69af0ce09449fdee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.553834855556488, Rank=18/101\n",
      "User 3912, Movie 318: Score=0.05139699950814247, Rank=61/101\n",
      "User 1878, Movie 1920: Score=0.8670216798782349, Rank=1/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.400\n",
      "Mean Rank: 16.9\n",
      "MRR: 0.219\n",
      "Epoch 17/30\n",
      "  Training Loss: 0.2582\n",
      "  Hit Ratio @ 10: 0.400\n",
      "  Mean Rank: 16.9\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f26220af3034f58aebd30719fd465e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 18/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e01088f4e81480abb1a3755cdd62406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6991475224494934, Rank=10/101\n",
      "User 3912, Movie 318: Score=0.05008773133158684, Rank=61/101\n",
      "User 1878, Movie 1920: Score=0.9223535060882568, Rank=1/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 15.7\n",
      "MRR: 0.192\n",
      "Epoch 18/30\n",
      "  Training Loss: 0.2636\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 15.7\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d391fe4af34f88bcd7e8cd57a4b5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 19/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fcf11b8f994ab985baf6c3930fa7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7045149207115173, Rank=12/101\n",
      "User 3912, Movie 318: Score=0.06868652999401093, Rank=59/101\n",
      "User 1878, Movie 1920: Score=0.7712274193763733, Rank=6/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.600\n",
      "Mean Rank: 16.0\n",
      "MRR: 0.139\n",
      "Epoch 19/30\n",
      "  Training Loss: 0.2596\n",
      "  Hit Ratio @ 10: 0.600\n",
      "  Mean Rank: 16.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a32a52a5bea4436b824e78d19b93f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 20/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f9ea3b833d415483900f22f622160d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.8025133609771729, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.04011140391230583, Rank=64/101\n",
      "User 1878, Movie 1920: Score=0.9016074538230896, Rank=2/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 16.6\n",
      "MRR: 0.162\n",
      "Epoch 20/30\n",
      "  Training Loss: 0.2531\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 16.6\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c58f389f4e444aa36bf55059fca643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 21/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1dc1564439471ab8307f78f6375c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6881752014160156, Rank=18/101\n",
      "User 3912, Movie 318: Score=0.04775451496243477, Rank=58/101\n",
      "User 1878, Movie 1920: Score=0.8799587488174438, Rank=3/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 16.2\n",
      "MRR: 0.119\n",
      "Epoch 21/30\n",
      "  Training Loss: 0.2492\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 16.2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b81f3c96cc4c879f0d60afdfbf3e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 22/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a4f39c570f4e0aaa96bc050f9d8cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.8704597353935242, Rank=6/101\n",
      "User 3912, Movie 318: Score=0.04305202141404152, Rank=61/101\n",
      "User 1878, Movie 1920: Score=0.8603580594062805, Rank=4/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 15.9\n",
      "MRR: 0.147\n",
      "Epoch 22/30\n",
      "  Training Loss: 0.2427\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 15.9\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164107df9d04427b85d61d4e91c1296f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 23/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b34d290f2a4a2ab5d6fe2b0ed195f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.8192331194877625, Rank=9/101\n",
      "User 3912, Movie 318: Score=0.04926421865820885, Rank=55/101\n",
      "User 1878, Movie 1920: Score=0.894798994064331, Rank=2/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.650\n",
      "Mean Rank: 15.4\n",
      "MRR: 0.144\n",
      "Epoch 23/30\n",
      "  Training Loss: 0.2381\n",
      "  Hit Ratio @ 10: 0.650\n",
      "  Mean Rank: 15.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c292e889914587aed81f76332cd456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 24/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e8101cf08f44a1b15ec4509c8ca3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.655774712562561, Rank=15/101\n",
      "User 3912, Movie 318: Score=0.05851385369896889, Rank=60/101\n",
      "User 1878, Movie 1920: Score=0.9485018253326416, Rank=1/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.300\n",
      "Mean Rank: 17.0\n",
      "MRR: 0.160\n",
      "Epoch 24/30\n",
      "  Training Loss: 0.2435\n",
      "  Hit Ratio @ 10: 0.300\n",
      "  Mean Rank: 17.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673a38935b8948f592fa43f2e45ac57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 25/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a20a1f78da47c88022c2d2f2093e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7790047526359558, Rank=13/101\n",
      "User 3912, Movie 318: Score=0.06829635053873062, Rank=52/101\n",
      "User 1878, Movie 1920: Score=0.9454501867294312, Rank=1/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.550\n",
      "Mean Rank: 14.4\n",
      "MRR: 0.177\n",
      "Epoch 25/30\n",
      "  Training Loss: 0.2317\n",
      "  Hit Ratio @ 10: 0.550\n",
      "  Mean Rank: 14.4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67674767d11e46928e916ad0a80f8c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 26/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1040d8c1bb2a465c82d7021a7b799852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.6422460675239563, Rank=15/101\n",
      "User 3912, Movie 318: Score=0.07014188170433044, Rank=52/101\n",
      "User 1878, Movie 1920: Score=0.9712156653404236, Rank=1/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 16.0\n",
      "MRR: 0.178\n",
      "Epoch 26/30\n",
      "  Training Loss: 0.2320\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 16.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96be5c6546644978b48b8f1432dda353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 27/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b504650981e4305beb1b5d60bc7e53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7106415629386902, Rank=14/101\n",
      "User 3912, Movie 318: Score=0.05613015219569206, Rank=61/101\n",
      "User 1878, Movie 1920: Score=0.9705905914306641, Rank=1/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 16.5\n",
      "MRR: 0.153\n",
      "Epoch 27/30\n",
      "  Training Loss: 0.2301\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 16.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3d40b6f90044db8f0127988498dff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 28/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4249f7018bd4feb8b41ae0603d46758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7642590999603271, Rank=14/101\n",
      "User 3912, Movie 318: Score=0.05563516169786453, Rank=59/101\n",
      "User 1878, Movie 1920: Score=0.9794411659240723, Rank=1/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.500\n",
      "Mean Rank: 16.5\n",
      "MRR: 0.156\n",
      "Epoch 28/30\n",
      "  Training Loss: 0.2245\n",
      "  Hit Ratio @ 10: 0.500\n",
      "  Mean Rank: 16.5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431407ca534045a996420cc8eed0ec66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 29/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cfc48d7926438fb9e089059abc7133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.7726737260818481, Rank=15/101\n",
      "User 3912, Movie 318: Score=0.10774926841259003, Rank=50/101\n",
      "User 1878, Movie 1920: Score=0.946782648563385, Rank=1/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.400\n",
      "Mean Rank: 17.3\n",
      "MRR: 0.150\n",
      "Epoch 29/30\n",
      "  Training Loss: 0.2225\n",
      "  Hit Ratio @ 10: 0.400\n",
      "  Mean Rank: 17.3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b7d93c1480432ab68d6803be4b25bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 30/30:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0f2181a00b496f8fa95819c0c19d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5608, Movie 3160: Score=0.42996346950531006, Rank=16/101\n",
      "User 3912, Movie 318: Score=0.04836602881550789, Rank=59/101\n",
      "User 1878, Movie 1920: Score=0.9466111063957214, Rank=1/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 20\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 20\n",
      "Hit Ratio @ 10: 0.450\n",
      "Mean Rank: 15.0\n",
      "MRR: 0.168\n",
      "Epoch 30/30\n",
      "  Training Loss: 0.2269\n",
      "  Hit Ratio @ 10: 0.450\n",
      "  Mean Rank: 15.0\n",
      "--------------------------------------------------\n",
      "Training with unique_per_user_hybrid completed!\n",
      "Final Hit Ratio @ 10: 0.450\n",
      "Final Mean Rank: 15.0\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "======================================================================\n",
      "unique_per_user_hybrid         | Hit Ratio: 0.450 | Mean Rank: 15.0\n",
      "\n",
      "All experiments completed!\n"
     ]
    }
   ],
   "source": [
    "sampling_strategies = [\n",
    "    (\"unique_per_user\", \"hybrid\"),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for sampling_strategy, neg_method in sampling_strategies:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training with {sampling_strategy.upper()} sampling + {neg_method.upper()} negatives\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Create optimized model with CORRECT feature dimensions\n",
    "    model = OptimizedNCF(\n",
    "        user_feature_dim=feature_processor.user_feature_dim,\n",
    "        movie_feature_dim=feature_processor.movie_feature_dim,\n",
    "        ratings=train_ratings, \n",
    "        feature_processor=feature_processor,\n",
    "        candidate_generator=candidate_gen,\n",
    "        negative_method=neg_method, \n",
    "        sampling_strategy=sampling_strategy\n",
    "    )\n",
    "\n",
    "    # Set up training parameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    dataloader = model.get_dataloader(batch_size=512, num_workers=4, num_negatives=4)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 30\n",
    "    \n",
    "    epoch_results = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in tqdm(dataloader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            # Move batch to device\n",
    "            user_input, item_input, labels = [x.to(device) for x in batch]\n",
    "            batch_device = (user_input, item_input, labels)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass and compute loss\n",
    "            loss = model.compute_loss(batch_device)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            hit_ratio, mrr, mean_rank = validate_model_with_features(\n",
    "                model, validation_ratings, validation_candidates, device, \n",
    "                total_users_to_test=20, k=10\n",
    "            )\n",
    "        \n",
    "        epoch_results.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_loss,\n",
    "            'hit_ratio': hit_ratio,\n",
    "            'mean_rank': mean_rank\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Training Loss: {avg_loss:.4f}\")\n",
    "        print(f\"  Hit Ratio @ 10: {hit_ratio:.3f}\")\n",
    "        print(f\"  Mean Rank: {mean_rank:.1f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Store results\n",
    "    strategy_name = f\"{sampling_strategy}_{neg_method}\"\n",
    "    results[strategy_name] = epoch_results\n",
    "    \n",
    "    print(f\"Training with {strategy_name} completed!\")\n",
    "    print(f\"Final Hit Ratio @ 10: {hit_ratio:.3f}\")\n",
    "    print(f\"Final Mean Rank: {mean_rank:.1f}\")\n",
    "\n",
    "# Summary of results\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for strategy_name, epoch_results in results.items():\n",
    "    final_result = epoch_results[-1]\n",
    "    print(f\"{strategy_name:30} | Hit Ratio: {final_result['hit_ratio']:.3f} | Mean Rank: {final_result['mean_rank']:.1f}\")\n",
    "\n",
    "print(\"\\nAll experiments completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9638ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model performance on test set...\n",
      "Precomputing candidates for 604 test users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e5bf376a6e4f1fb72134f183411aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing test candidates:   0%|          | 0/604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ac977fb9a645e89bb2065684d08cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 2898, Movie 2502: Score=0.8982254266738892, Rank=4/101\n",
      "User 4689, Movie 3793: Score=0.9394497275352478, Rank=1/101\n",
      "User 3138, Movie 1580: Score=0.1508067548274994, Rank=38/101\n",
      "\n",
      "Validation Summary:\n",
      "Total test cases: 50\n",
      "Skipped cases: 0\n",
      "Valid cases processed: 50\n",
      "Hit Ratio @ 10: 0.640\n",
      "Mean Rank: 15.6\n",
      "MRR: 0.287\n",
      "TEST SET RESULTS:\n",
      "Hit Ratio @ 10: 0.640\n",
      "Mean Rank: 15.6\n",
      "MRR: 0.287\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing model performance on test set...\")\n",
    "\n",
    "def precompute_test_candidates(test_ratings, candidate_method=\"hybrid\", num_candidates=100):\n",
    "    test_users = test_ratings['user_id'].unique()\n",
    "    precomputed_candidates = {}\n",
    "    \n",
    "    print(f\"Precomputing candidates for {len(test_users)} test users...\")\n",
    "    \n",
    "    for user_id in tqdm(test_users, desc=\"Precomputing test candidates\"):\n",
    "        candidates = generate_candidates(user_id, method=candidate_method, num_candidates=num_candidates)\n",
    "        precomputed_candidates[user_id] = candidates\n",
    "    \n",
    "    return precomputed_candidates\n",
    "\n",
    "test_candidates = precompute_test_candidates(test_ratings, candidate_method=\"hybrid\", num_candidates=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(f\"Evaluating on test set...\")\n",
    "    test_hit_ratio, test_mrr, test_mean_rank = validate_model_with_features(\n",
    "        model, test_ratings, test_candidates, device, \n",
    "        total_users_to_test=50, k=10\n",
    "    )\n",
    "\n",
    "print(f\"TEST SET RESULTS:\")\n",
    "print(f\"Hit Ratio @ 10: {test_hit_ratio:.3f}\")\n",
    "print(f\"Mean Rank: {test_mean_rank:.1f}\")\n",
    "print(f\"MRR: {test_mrr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc89c335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cold Start Recommender initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "class ColdStartRecommender:\n",
    "    \"\"\"\n",
    "    Cold Start Recommendation System for new users\n",
    "    \n",
    "    Handles recommendations for users with limited or no interaction history\n",
    "    by leveraging user demographics, initial ratings, and content-based filtering.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, trained_model, feature_processor, candidate_generator, movies_df):\n",
    "        self.model = trained_model\n",
    "        self.feature_processor = feature_processor\n",
    "        self.candidate_generator = candidate_generator\n",
    "        self.movies_df = movies_df\n",
    "        self.device = next(trained_model.parameters()).device\n",
    "        \n",
    "    def create_user_features(self, user_demographics):\n",
    "        \"\"\"\n",
    "        Create user feature vector from demographics\n",
    "        \n",
    "        Args:\n",
    "            user_demographics: dict with keys: 'gender', 'age', 'occupation'\n",
    "                - gender: 'M' or 'F'\n",
    "                - age: int (1, 18, 25, 35, 45, 50, 56)\n",
    "                - occupation: int (0-20)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: User feature vector\n",
    "        \"\"\"\n",
    "        gender_encoded = 1.0 if user_demographics['gender'] == 'M' else 0.0\n",
    "        \n",
    "        # Create age one-hot (7 categories)\n",
    "        age_categories = [1, 18, 25, 35, 45, 50, 56]\n",
    "        age_onehot = [1.0 if user_demographics['age'] == cat else 0.0 for cat in age_categories]\n",
    "        \n",
    "        # Create occupation one-hot (21 categories: 0-20)\n",
    "        occupation_onehot = [1.0 if user_demographics['occupation'] == i else 0.0 for i in range(21)]\n",
    "        \n",
    "        # Combine all features\n",
    "        feature_vector = [gender_encoded] + age_onehot + occupation_onehot\n",
    "        \n",
    "        return torch.tensor(feature_vector, dtype=torch.float32)\n",
    "    \n",
    "    def get_similar_users_by_demographics(self, user_demographics, top_k=50):\n",
    "        \"\"\"\n",
    "        Find users with similar demographics for collaborative filtering\n",
    "        \n",
    "        Args:\n",
    "            user_demographics: dict with user demographic info\n",
    "            top_k: number of similar users to return\n",
    "            \n",
    "        Returns:\n",
    "            list: user_ids of similar users\n",
    "        \"\"\"\n",
    "        similar_users = []\n",
    "        \n",
    "        # Simple demographic matching - can be made more sophisticated\n",
    "        for user_id, cached_features in self.feature_processor.user_features_cache.items():\n",
    "            # Check gender match (first feature)\n",
    "            gender_match = (cached_features[0].item() == (1.0 if user_demographics['gender'] == 'M' else 0.0))\n",
    "            \n",
    "            # Check age category match (positions 1-7)\n",
    "            age_categories = [1, 18, 25, 35, 45, 50, 56]\n",
    "            user_age_idx = age_categories.index(user_demographics['age']) if user_demographics['age'] in age_categories else -1\n",
    "            if user_age_idx >= 0:\n",
    "                age_match = cached_features[1 + user_age_idx].item() == 1.0\n",
    "            else:\n",
    "                age_match = False\n",
    "            \n",
    "            # Check occupation match (positions 8-28)\n",
    "            occ_match = False\n",
    "            if 0 <= user_demographics['occupation'] <= 20:\n",
    "                occ_match = cached_features[8 + user_demographics['occupation']].item() == 1.0\n",
    "            \n",
    "            # Score based on matches (prioritize age and occupation)\n",
    "            score = 0\n",
    "            if gender_match: score += 1\n",
    "            if age_match: score += 2\n",
    "            if occ_match: score += 3\n",
    "            \n",
    "            if score >= 2:  # Require at least age or occupation match\n",
    "                similar_users.append((user_id, score))\n",
    "        \n",
    "        # Sort by score and return top_k\n",
    "        similar_users.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [user_id for user_id, _ in similar_users[:top_k]]\n",
    "    \n",
    "    def generate_cold_start_candidates(self, user_demographics, user_ratings=None, num_candidates=100):\n",
    "        \"\"\"\n",
    "        Generate candidate movies for cold start scenario\n",
    "        \n",
    "        Args:\n",
    "            user_demographics: dict with user demographic info\n",
    "            user_ratings: list of (movie_id, rating) tuples for initial ratings\n",
    "            num_candidates: number of candidates to generate\n",
    "            \n",
    "        Returns:\n",
    "            list: candidate movie IDs\n",
    "        \"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        if user_ratings is None or len(user_ratings) == 0:\n",
    "            # Pure cold start - no ratings yet\n",
    "            # Use popularity + demographic-based recommendations\n",
    "            \n",
    "            # Get popular movies\n",
    "            popular_candidates = self.candidate_generator.generate_popularity_candidates(\n",
    "                user_id=-1,  # dummy user_id\n",
    "                num_candidates=num_candidates//2\n",
    "            )\n",
    "            candidates.extend(popular_candidates)\n",
    "            \n",
    "            # Get recommendations based on similar users' preferences\n",
    "            similar_users = self.get_similar_users_by_demographics(user_demographics)\n",
    "            if similar_users:\n",
    "                # Get popular movies among similar users\n",
    "                similar_user_movies = []\n",
    "                for similar_user_id in similar_users[:10]:  # Top 10 similar users\n",
    "                    user_movies = self.candidate_generator.user_interacted_items.get(similar_user_id, [])\n",
    "                    similar_user_movies.extend(user_movies)\n",
    "                \n",
    "                # Count frequency and get most popular among similar users\n",
    "                from collections import Counter\n",
    "                movie_counts = Counter(similar_user_movies)\n",
    "                demographic_candidates = [movie_id for movie_id, _ in movie_counts.most_common(num_candidates//2)]\n",
    "                candidates.extend(demographic_candidates)\n",
    "        \n",
    "        else:\n",
    "            # Warm cold start - user has some initial ratings\n",
    "            # Use content-based recommendations based on liked movies\n",
    "            \n",
    "            liked_movies = [movie_id for movie_id, rating in user_ratings if rating >= 4]\n",
    "            \n",
    "            if liked_movies:\n",
    "                # Content-based recommendations using movie genres\n",
    "                content_candidates = []\n",
    "                \n",
    "                # Get genres of liked movies\n",
    "                liked_genres = []\n",
    "                for movie_id in liked_movies:\n",
    "                    if movie_id in self.candidate_generator.movie_to_genres:\n",
    "                        liked_genres.extend(self.candidate_generator.movie_to_genres[movie_id])\n",
    "                \n",
    "                # Count genre preferences\n",
    "                from collections import Counter\n",
    "                genre_preferences = Counter(liked_genres)\n",
    "                \n",
    "                # Find movies with similar genres\n",
    "                for movie_id, genres in self.candidate_generator.movie_to_genres.items():\n",
    "                    if movie_id not in liked_movies:  # Don't recommend already rated movies\n",
    "                        score = sum(genre_preferences.get(genre, 0) for genre in genres)\n",
    "                        if score > 0:\n",
    "                            content_candidates.append((movie_id, score))\n",
    "                \n",
    "                # Sort by content score and take top candidates\n",
    "                content_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "                candidates.extend([movie_id for movie_id, _ in content_candidates[:num_candidates//2]])\n",
    "            \n",
    "            # Add some popular movies as backup\n",
    "            popular_candidates = self.candidate_generator.generate_popularity_candidates(\n",
    "                user_id=-1,\n",
    "                num_candidates=num_candidates//2\n",
    "            )\n",
    "            candidates.extend(popular_candidates)\n",
    "        \n",
    "        # Remove duplicates while preserving order\n",
    "        seen = set()\n",
    "        unique_candidates = []\n",
    "        for movie_id in candidates:\n",
    "            if movie_id not in seen:\n",
    "                seen.add(movie_id)\n",
    "                unique_candidates.append(movie_id)\n",
    "        \n",
    "        return unique_candidates[:num_candidates]\n",
    "    \n",
    "    def recommend_for_new_user(self, user_demographics, user_ratings=None, num_recommendations=10):\n",
    "        \"\"\"\n",
    "        Generate recommendations for a new user\n",
    "        \n",
    "        Args:\n",
    "            user_demographics: dict with keys 'gender', 'age', 'occupation'\n",
    "            user_ratings: list of (movie_id, rating) tuples for initial ratings (optional)\n",
    "            num_recommendations: number of recommendations to return\n",
    "            \n",
    "        Returns:\n",
    "            list: list of (movie_id, title, predicted_score) tuples\n",
    "        \"\"\"\n",
    "        # Create user feature vector\n",
    "        user_features = self.create_user_features(user_demographics)\n",
    "        user_features = user_features.unsqueeze(0).to(self.device)  # Add batch dimension\n",
    "        \n",
    "        # Generate candidate movies\n",
    "        candidates = self.generate_cold_start_candidates(\n",
    "            user_demographics, \n",
    "            user_ratings, \n",
    "            num_candidates=min(200, len(self.movies_df))\n",
    "        )\n",
    "        \n",
    "        # Score candidates using the NCF model\n",
    "        movie_scores = []\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for movie_id in candidates:\n",
    "                if movie_id in self.feature_processor.movie_features_cache:\n",
    "                    # Get movie features\n",
    "                    movie_features = self.feature_processor.get_movie_features(movie_id)\n",
    "                    movie_features = movie_features.unsqueeze(0).to(self.device)\n",
    "                    \n",
    "                    # Predict score using NCF model\n",
    "                    score = self.model(user_features, movie_features).item()\n",
    "                    \n",
    "                    # Get movie title\n",
    "                    movie_title = self.movies_df[self.movies_df['movie_id'] == movie_id]['title'].iloc[0]\n",
    "                    \n",
    "                    movie_scores.append((movie_id, movie_title, score))\n",
    "        \n",
    "        # Sort by predicted score and return top recommendations\n",
    "        movie_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Filter out movies user has already rated\n",
    "        if user_ratings:\n",
    "            rated_movie_ids = {movie_id for movie_id, _ in user_ratings}\n",
    "            movie_scores = [(mid, title, score) for mid, title, score in movie_scores \n",
    "                           if mid not in rated_movie_ids]\n",
    "        \n",
    "        return movie_scores[:num_recommendations]\n",
    "    \n",
    "    def get_onboarding_movies(self, num_movies=10):\n",
    "        \"\"\"\n",
    "        Get diverse, popular movies for new user onboarding/rating collection\n",
    "        \n",
    "        Args:\n",
    "            num_movies: number of movies to return for rating\n",
    "            \n",
    "        Returns:\n",
    "            list: list of (movie_id, title, genres) tuples\n",
    "        \"\"\"\n",
    "        # Get popular movies from different genres for diversity\n",
    "        popular_movies = self.candidate_generator.generate_popularity_candidates(\n",
    "            user_id=-1, \n",
    "            num_candidates=100\n",
    "        )\n",
    "        \n",
    "        # Group by genres to ensure diversity\n",
    "        genre_movies = {}\n",
    "        selected_movies = []\n",
    "        \n",
    "        for movie_id in popular_movies:\n",
    "            if movie_id in self.candidate_generator.movie_to_genres:\n",
    "                movie_genres = self.candidate_generator.movie_to_genres[movie_id]\n",
    "                movie_title = self.movies_df[self.movies_df['movie_id'] == movie_id]['title'].iloc[0]\n",
    "                movie_genres_str = self.movies_df[self.movies_df['movie_id'] == movie_id]['genres'].iloc[0]\n",
    "                \n",
    "                # Add to genre groups\n",
    "                for genre in movie_genres:\n",
    "                    if genre not in genre_movies:\n",
    "                        genre_movies[genre] = []\n",
    "                    genre_movies[genre].append((movie_id, movie_title, movie_genres_str))\n",
    "        \n",
    "        # Select diverse movies (one from each genre initially)\n",
    "        used_genres = set()\n",
    "        for genre, movies in genre_movies.items():\n",
    "            if len(selected_movies) < num_movies and genre not in used_genres:\n",
    "                selected_movies.append(movies[0])  # Take the most popular from this genre\n",
    "                used_genres.add(genre)\n",
    "        \n",
    "        # Fill remaining slots with most popular movies\n",
    "        for movie_id in popular_movies:\n",
    "            if len(selected_movies) >= num_movies:\n",
    "                break\n",
    "            \n",
    "            movie_title = self.movies_df[self.movies_df['movie_id'] == movie_id]['title'].iloc[0]\n",
    "            movie_genres_str = self.movies_df[self.movies_df['movie_id'] == movie_id]['genres'].iloc[0]\n",
    "            \n",
    "            movie_tuple = (movie_id, movie_title, movie_genres_str)\n",
    "            if movie_tuple not in selected_movies:\n",
    "                selected_movies.append(movie_tuple)\n",
    "        \n",
    "        return selected_movies[:num_movies]\n",
    "\n",
    "# Initialize the cold start recommender with the trained model\n",
    "cold_start_recommender = ColdStartRecommender(\n",
    "    trained_model=model,\n",
    "    feature_processor=feature_processor,\n",
    "    candidate_generator=candidate_gen,\n",
    "    movies_df=movies\n",
    ")\n",
    "\n",
    "print(\"Cold Start Recommender initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "736eaa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COLD START RECOMMENDATION SYSTEM DEMONSTRATION\n",
      "================================================================================\n",
      "\n",
      "1. PURE COLD START SCENARIO\n",
      "--------------------------------------------------\n",
      "New User Demographics: {'gender': 'M', 'age': 25, 'occupation': 4}\n",
      "\n",
      "Top 10 Cold Start Recommendations:\n",
      " 1. Platoon (1986)                                     (Score: 0.991)\n",
      " 2. Doctor Zhivago (1965)                              (Score: 0.988)\n",
      " 3. Sling Blade (1996)                                 (Score: 0.981)\n",
      " 4. Maltese Falcon, The (1941)                         (Score: 0.978)\n",
      " 5. Apocalypse Now (1979)                              (Score: 0.977)\n",
      " 6. Rebel Without a Cause (1955)                       (Score: 0.976)\n",
      " 7. Producers, The (1968)                              (Score: 0.969)\n",
      " 8. Life Is Beautiful (La Vita  bella) (1997)         (Score: 0.967)\n",
      " 9. X-Men (2000)                                       (Score: 0.966)\n",
      "10. Akira (1988)                                       (Score: 0.960)\n",
      "\n",
      "\n",
      "2. ONBOARDING MOVIES FOR RATING COLLECTION\n",
      "--------------------------------------------------\n",
      "Movies to show new user for initial ratings (diverse genres):\n",
      "1. American Beauty (1999)                   | Genres: Comedy|Drama\n",
      "2. American Beauty (1999)                   | Genres: Comedy|Drama\n",
      "3. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "4. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "5. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "6. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "7. Star Wars: Episode VI - Return of the Jedi (1983) | Genres: Action|Adventure|Romance|Sci-Fi|War\n",
      "8. Star Wars: Episode IV - A New Hope (1977) | Genres: Action|Adventure|Fantasy|Sci-Fi\n",
      "\n",
      "\n",
      "3. WARM COLD START SCENARIO\n",
      "--------------------------------------------------\n",
      "User's initial ratings:\n",
      "  American Beauty (1999)                             - Rating: 5/5\n",
      "  American Beauty (1999)                             - Rating: 4/5\n",
      "  Star Wars: Episode VI - Return of the Jedi (1983)  - Rating: 2/5\n",
      "  Star Wars: Episode VI - Return of the Jedi (1983)  - Rating: 4/5\n",
      "\n",
      "Top 10 Recommendations after initial ratings:\n",
      " 1. Rob Roy (1995)                                     (Score: 0.987)\n",
      " 2. Life Is Beautiful (La Vita  bella) (1997)         (Score: 0.967)\n",
      " 3. X-Men (2000)                                       (Score: 0.966)\n",
      " 4. Singles (1992)                                     (Score: 0.963)\n",
      " 5. Eat Drink Man Woman (1994)                         (Score: 0.928)\n",
      " 6. Toy Story 2 (1999)                                 (Score: 0.924)\n",
      " 7. Wings of Desire (Der Himmel ber Berlin) (1987)    (Score: 0.922)\n",
      " 8. Pretty in Pink (1986)                              (Score: 0.915)\n",
      " 9. Thelma & Louise (1991)                             (Score: 0.911)\n",
      "10. Reality Bites (1994)                               (Score: 0.911)\n",
      "\n",
      "\n",
      "4. COMPARISON: Different User Demographics\n",
      "--------------------------------------------------\n",
      "Different User Demographics: {'gender': 'F', 'age': 45, 'occupation': 0}\n",
      "\n",
      "Top 5 Recommendations for different demographic:\n",
      "1. Mission to Mars (2000)                             (Score: 0.981)\n",
      "2. Shanghai Noon (2000)                               (Score: 0.966)\n",
      "3. Life Is Beautiful (La Vita  bella) (1997)         (Score: 0.952)\n",
      "4. X-Men (2000)                                       (Score: 0.950)\n",
      "5. Grumpy Old Men (1993)                              (Score: 0.925)\n",
      "\n",
      "================================================================================\n",
      "Cold Start Recommendation Demonstration Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# DEMONSTRATION: Cold Start Recommendation Examples\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COLD START RECOMMENDATION SYSTEM DEMONSTRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Example 1: Pure Cold Start - New user with only demographics\n",
    "print(\"\\n1. PURE COLD START SCENARIO\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "new_user_demographics = {\n",
    "    'gender': 'M',     # Male\n",
    "    'age': 25,         # 25 years old  \n",
    "    'occupation': 4    # College/grad student (based on MovieLens occupation codes)\n",
    "}\n",
    "\n",
    "print(f\"New User Demographics: {new_user_demographics}\")\n",
    "\n",
    "# Get recommendations without any ratings\n",
    "cold_start_recommendations = cold_start_recommender.recommend_for_new_user(\n",
    "    user_demographics=new_user_demographics,\n",
    "    user_ratings=None,  # No ratings yet\n",
    "    num_recommendations=10\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 10 Cold Start Recommendations:\")\n",
    "for i, (movie_id, title, score) in enumerate(cold_start_recommendations, 1):\n",
    "    print(f\"{i:2d}. {title:<50} (Score: {score:.3f})\")\n",
    "\n",
    "# Example 2: Get onboarding movies for initial rating collection\n",
    "print(f\"\\n\\n2. ONBOARDING MOVIES FOR RATING COLLECTION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "onboarding_movies = cold_start_recommender.get_onboarding_movies(num_movies=8)\n",
    "\n",
    "print(\"Movies to show new user for initial ratings (diverse genres):\")\n",
    "for i, (movie_id, title, genres) in enumerate(onboarding_movies, 1):\n",
    "    print(f\"{i}. {title:<40} | Genres: {genres}\")\n",
    "\n",
    "# Example 3: Warm Cold Start - User has provided some initial ratings\n",
    "print(f\"\\n\\n3. WARM COLD START SCENARIO\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Simulate user rating some of the onboarding movies\n",
    "initial_ratings = [\n",
    "    (onboarding_movies[0][0], 5),  # Loved the first movie\n",
    "    (onboarding_movies[1][0], 4),  # Liked the second movie\n",
    "    (onboarding_movies[2][0], 2),  # Didn't like the third movie\n",
    "    (onboarding_movies[3][0], 4),  # Liked the fourth movie\n",
    "]\n",
    "\n",
    "print(\"User's initial ratings:\")\n",
    "for movie_id, rating in initial_ratings:\n",
    "    movie_title = movies[movies['movie_id'] == movie_id]['title'].iloc[0]\n",
    "    print(f\"  {movie_title:<50} - Rating: {rating}/5\")\n",
    "\n",
    "# Get improved recommendations based on initial ratings\n",
    "warm_recommendations = cold_start_recommender.recommend_for_new_user(\n",
    "    user_demographics=new_user_demographics,\n",
    "    user_ratings=initial_ratings,\n",
    "    num_recommendations=10\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 10 Recommendations after initial ratings:\")\n",
    "for i, (movie_id, title, score) in enumerate(warm_recommendations, 1):\n",
    "    print(f\"{i:2d}. {title:<50} (Score: {score:.3f})\")\n",
    "\n",
    "print(f\"\\n\\n4. COMPARISON: Different User Demographics\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Example with different demographics\n",
    "female_user_demographics = {\n",
    "    'gender': 'F',     # Female\n",
    "    'age': 45,         # 45 years old\n",
    "    'occupation': 0    # Other/not specified\n",
    "}\n",
    "\n",
    "print(f\"Different User Demographics: {female_user_demographics}\")\n",
    "\n",
    "female_recommendations = cold_start_recommender.recommend_for_new_user(\n",
    "    user_demographics=female_user_demographics,\n",
    "    user_ratings=None,\n",
    "    num_recommendations=5\n",
    ")\n",
    "\n",
    "print(f\"\\nTop 5 Recommendations for different demographic:\")\n",
    "for i, (movie_id, title, score) in enumerate(female_recommendations, 1):\n",
    "    print(f\"{i}. {title:<50} (Score: {score:.3f})\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Cold Start Recommendation Demonstration Complete!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd8db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
