{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae814a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cddc2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a35909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph-checkpoint-sqlite in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (2.0.11)\n",
      "Requirement already satisfied: aiosqlite>=0.20 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langgraph-checkpoint-sqlite) (0.21.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.21 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langgraph-checkpoint-sqlite) (2.1.1)\n",
      "Requirement already satisfied: sqlite-vec>=0.1.6 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langgraph-checkpoint-sqlite) (0.1.6)\n",
      "Requirement already satisfied: langchain-core>=0.2.38 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.3.76)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.10.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from aiosqlite>=0.20->langgraph-checkpoint-sqlite) (4.15.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.4.28)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.24.0)\n",
      "Requirement already satisfied: anyio in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (4.10.0)\n",
      "Requirement already satisfied: certifi in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/kevin/miniconda3/envs/recommendation-ai/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph-checkpoint-sqlite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38551229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eeab5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c282e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81cbd318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Optional\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import json \n",
    "class UserProfile(BaseModel):\n",
    "    name: Optional[str]\n",
    "    age: Optional[int]\n",
    "    gender: Optional[str]\n",
    "    occupation: Optional[str]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    user_profile: UserProfile\n",
    "\n",
    "ONBOARDING_USER_CREATE_PROMPT = \"\"\"You are the Big Boss bot: a helpful assistant that recommends movies to users.\n",
    " In the first step, you will ask user information to create a user profile. The information you need to ask is:\n",
    " - name\n",
    " - age\n",
    " - gender\n",
    " - occupation\n",
    "\n",
    "Currently the user profile that you have is:\n",
    "{user_profile}\n",
    "\n",
    "Ask the user for the information that you don't have. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "USER_CREATE_STATE_PROMPT = \"\"\"You are the Big Boss bot: a helpful assistant that recommends movies to users.\n",
    "You already have a user profile with the following information:\n",
    "{user_profile}\n",
    "\n",
    "Now you will thanks the user for the information and ask for the next information.\n",
    "\"\"\"\n",
    "\n",
    "EXTRACTION_USER_CREATE_PROMPT = \"\"\"You are an extractor of user profile from a text.\n",
    " The text is a conversation between a user and a bot.\n",
    " The user profile is a dictionary with the following keys:\n",
    " - name\n",
    " - age\n",
    " - gender\n",
    " - occupation\n",
    "You will receive a conversation message and you will extract the user profile from the message. Extract the user profile to a JSON object. \n",
    "Example:\n",
    "```\n",
    "User: Hello, my name is John Doe. I am 30 years old. I am a software engineer.\n",
    "Bot: Hello, John. Nice to meet you.\n",
    "```\n",
    "The user profile is:\n",
    "```json\n",
    "{\n",
    "    \"name\": \"John Doe\",\n",
    "    \"age\": 30,\n",
    "    \"gender\": \"male\",\n",
    "    \"occupation\": \"software engineer\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f52572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, checkpointer):\n",
    "        self.rec_url = os.getenv(\"RECOMMENDATION_API_URL\")\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"user_profile_prompt\", self.user_profile_prompt)\n",
    "        graph.add_node(\"user_profile_extraction\", self.user_profile_extraction)\n",
    "        graph.add_node(\"create_user_profile\", self.create_user_profile)\n",
    "\n",
    "        graph.add_edge(\"user_profile_prompt\", \"user_profile_extraction\")\n",
    "        graph.add_conditional_edges(\"user_profile_extraction\", self.exists_user_profile, {True: END, False: \"user_profile_prompt\"})\n",
    "        graph.add_edge(\"user_profile_extraction\", \"create_user_profile\")\n",
    "        graph.add_edge(\"create_user_profile\", END)\n",
    "\n",
    "\n",
    "        graph.set_entry_point(\"user_profile_prompt\")\n",
    "\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.model = ChatOpenAI(model=\"gpt-5-nano\", temperature=0)\n",
    "\n",
    "    def exists_user_profile(self, state: AgentState) -> bool:\n",
    "        user_profile = state.get(\"user_profile\")\n",
    "        if user_profile is None:\n",
    "            return False\n",
    "        return user_profile.age is not None and user_profile.gender is not None and user_profile.occupation is not None\n",
    "\n",
    "    def user_profile_prompt(self, state: AgentState) -> AgentState:\n",
    "        print(\"in user_profile_prompt\")\n",
    "        profile = state.get(\"user_profile\")\n",
    "        profile_json = json.dumps(profile.model_dump() if profile else {}, ensure_ascii=False)\n",
    "        prompt = ChatPromptTemplate.from_template(ONBOARDING_USER_CREATE_PROMPT)\n",
    "\n",
    "\n",
    "        rendered = prompt.format(user_profile=profile_json, user_input=state['messages'][-1].content)\n",
    "        messages = [rendered] + state['messages']\n",
    "        model_message = self.model.invoke(messages)\n",
    "        return {'messages': [model_message]}\n",
    "\n",
    "    def create_user_profile(self, state: AgentState) -> AgentState:\n",
    "        print(\"in create_user_profile\")\n",
    "        url = self.rec_url.rstrip(\"/\") + \"/users/\"\n",
    "        profile = state.get(\"user_profile\")\n",
    "        if not profile:\n",
    "            raise ValueError(\"User profile is not found\")\n",
    "        name = profile.name\n",
    "        age = profile.age\n",
    "        gender = profile.gender\n",
    "        occupation = profile.occupation\n",
    "        payload = {\n",
    "            \"name\": name,\n",
    "            \"age\": age,\n",
    "            \"gender\": gender,\n",
    "            \"occupation\": occupation,\n",
    "        }\n",
    "        r = requests.post(url, json=payload, timeout=30)\n",
    "        return { \"messages\": [r.json()], \"user_profile\": profile}\n",
    "\n",
    "\n",
    "    def user_profile_extraction(self, state: AgentState) -> AgentState:\n",
    "        print(\"in user_profile_extraction\")\n",
    "        parser = JsonOutputParser()\n",
    "        messages = [SystemMessage(content=EXTRACTION_USER_CREATE_PROMPT)] + state[\"messages\"]\n",
    "        model_message = self.model.invoke(messages)\n",
    "        content = model_message.content\n",
    "        data = parser.parse(content)\n",
    "\n",
    "        profile = UserProfile(\n",
    "            name=data.get(\"name\"),\n",
    "            age=int(data.get(\"age\")) if data.get(\"age\") else None,\n",
    "            gender=data.get(\"gender\"),\n",
    "            occupation=data.get(\"occupation\"),\n",
    "        )\n",
    "\n",
    "\n",
    "        return {\"messages\": [model_message], \"user_profile\": profile} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "211aeec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=Agent(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f53947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in user_profile_prompt\n",
      "[AIMessage(content='Nice to meet you! I have your details as: age 30, gender male, occupation software engineer. What is your name so I can complete your profile? If you prefer, you can share a preferred name or nickname.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 439, 'prompt_tokens': 112, 'total_tokens': 551, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CGb84Ra3uoM0TVdDgZRsfQmY1AigE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b8151a0b-9d4b-4a8b-814a-3da7b31b62af-0', usage_metadata={'input_tokens': 112, 'output_tokens': 439, 'total_tokens': 551, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})]\n",
      "in user_profile_extraction\n",
      "[AIMessage(content='{\\n  \"name\": null,\\n  \"age\": 30,\\n  \"gender\": \"male\",\\n  \"occupation\": \"software engineer\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 935, 'prompt_tokens': 241, 'total_tokens': 1176, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CGb877xvOHPjg7oBav6htJf9Pb5w3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9f20207a-9505-473d-933a-0d3eb26e6a71-0', usage_metadata={'input_tokens': 241, 'output_tokens': 935, 'total_tokens': 1176, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})]\n",
      "in create_user_profile\n",
      "[{'detail': [{'type': 'string_type', 'loc': ['body', 'name'], 'msg': 'Input should be a valid string', 'input': None}, {'type': 'int_parsing', 'loc': ['body', 'occupation'], 'msg': 'Input should be a valid integer, unable to parse string as an integer', 'input': 'software engineer'}]}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hello. 30 years, male\"),\n",
    "    AIMessage(content=\"Please tell your occupation\"),\n",
    "    HumanMessage(content=\"I am a software engineer\")\n",
    "]\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in agent.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e340e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b5e5bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastapi'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastAPI\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_server\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnest_asyncio\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01muvicorn\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'fastapi'"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from langgraph.server import create_server\n",
    "import nest_asyncio, uvicorn\n",
    "\n",
    "# reuse your existing memory/Agent\n",
    "app = create_server(agent.graph)  # agent.graph is your compiled graph\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, host=\"127.0.0.1\", port=8123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d54a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendation-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
